{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Pauta_Tarea_1.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"zbrMqMPyncTC"},"source":["# **Tarea 1 - CC6205 Natural Language Processing üìö**\n","\n","**Integrantes:**\n","\n","**Fecha l√≠mite de entrega üìÜ:** Lunes 05 de Abril.\n","\n","**Tiempo estimado de dedicaci√≥n:**\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"D1HFX-9PpxF9"},"source":["` ` \n","\n","\n","Bienvenid@s a la primera tarea en el curso de Natural Language Processing (NLP). Esta tarea tiene como objetivo evaluar los contenidos te√≥ricos de las primeras semanas de clases, enfocado principalmente en ***Information Retrieval (IR)*** y ***Vector Space Models***. Si a√∫n no han visto las clases, se recomienda visitar los links de las referencias.\n","\n","La tarea consta de una parte te√≥rica que busca evaluar conceptos vistos en clases. Seguido por una parte pr√°ctica con el f√≠n de introducirlos a la programaci√≥n en Python enfocada en NLP. \n","\n","` ` \n","\n","\n","\n","\n","**Instrucciones:**\n","- La tarea se realiza en grupos de **m√°ximo** 2 personas. Puede ser invidivual pero no es recomendable.\n","- La entrega es a trav√©s de u-cursos a m√°s tardar el d√≠a estipulado arriba. No se aceptan atrasos.\n","- El formato de entrega es este mismo Jupyter Notebook.\n","- Al momento de la revisi√≥n tu c√≥digo ser√° ejecutado. Por favor verifica que tu entrega no tenga errores de compilaci√≥n. \n","- Est√° **PROHIBIDO** usar cualquier librer√≠a que implemente los algoritmos pedidos (Spacy, scikit, etc). S√≥lo se podr√°n utilizar las librer√≠as importadas al inicio de la secci√≥n de pr√°ctica.\n","- En el horario de auxiliar pueden realizar consultas acerca de la tarea a trav√©s del canal de Discord del curso. \n","\n","\n","\n","Ahora s√≠, empecemos! üòÑüöÄ\n","\n","` ` \n","\n","**Referencias:**\n","\n","\n","Slides:\n","    \n","- [Introducci√≥n al curso](https://github.com/dccuchile/CC6205/blob/master/slides/NLP-introduction.pdf)\n","- [Vector Space Model / Information Retrieval](https://github.com/dccuchile/CC6205/blob/master/slides/NLP-IR.pdf)    \n","\n","Videos: \n","\n","- [CC6205 - Procesamiento de Lenguaje Natural: CC6205 - Procesamiento de Lenguaje Natural: Introducci√≥n parte I](https://www.youtube.com/watch?v=HEKTNOttGvU)\n","- [CC6205 - Procesamiento de Lenguaje Natural: CC6205 - Procesamiento de Lenguaje Natural: Introducci√≥n parte II](https://www.youtube.com/watch?v=P8cwnI-f-Kg)\n","- [CC6205 - Procesamiento de Lenguaje Natural: Vector Space Model and Information Retrieval parte 1](https://youtu.be/FXIVClF370w)\n","- [CC6205 - Procesamiento de Lenguaje Natural: Vector Space Model and Information Retrieval parte 2](https://youtu.be/f8nG1EMmPZk)\n","\n","` ` \n","\n"]},{"cell_type":"markdown","metadata":{"id":"hJshpe1yrKJr"},"source":["## **1 - Preguntas te√≥ricas üìï (2 puntos).** ##\n","\n","\n","\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"MBEDKXBPoA7w"},"source":["Las siguientes celdas contienen preguntas acerca del contenido visto en clases y en el material del curso.  Contestar cada pregunta en su celda correspondiente y **no extenderse m√°s de 5 lineas** . üôè\n","` ` "]},{"cell_type":"markdown","metadata":{"id":"xNJPR1kMrw9R"},"source":["**Pregunta 1 (0.5 puntos): ¬øPor qu√© el an√°lisis del lenguaje humano es una tarea compleja? Mencione dos razones.**\n","\n"]},{"cell_type":"markdown","metadata":{"id":"mlTBYHEptdde"},"source":["Porque es extremadamente complejo entender formalmente y describir las reglas que rigen el lenguaje. El lenguaje humano es muy ambiguo y es din√°mico.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Zv8yjG94r6FC"},"source":["**Pregunta 2 (0.5 puntos): ¬øCu√°l es la diferencia entre Natural Language Processing (NLP) y Computational Linguistics?**"]},{"cell_type":"markdown","metadata":{"id":"0vmC3uYHtctH"},"source":["NLP desarrolla m√©todos y modelos para resolver problemas pr√°cticos (tasks) del lenguaje. Por otro lado, CL es una disciplina que a trav√©s de m√©todos estad√≠sticos y computacionales busca entender procesos y formalismos del lenguaje humano.\n"]},{"cell_type":"markdown","metadata":{"id":"U-0imOaFsRK5"},"source":["**Pregunta 3 (0.5 puntos): ¬øQu√© es el Machine Learning supersivado? ¬øPor qu√© es importante para el campo de NLP?**"]},{"cell_type":"markdown","metadata":{"id":"kY6mfCE7tb1x"},"source":["Corresponde a un paradigma de aprendizaje en el √°rea de Machine Learning. Se basa en la creaci√≥n de algoritmos capaces de reconocer las relaciones entre variables de entradas y de salida a partir de un conjunto de datos etiquetados previamente. Es muy √∫til en el √°rea de NLP por la dificultad de formalizar el lenguaje, entregando excelentes resultados en la mayor√≠a de las tasks existentes."]},{"cell_type":"markdown","metadata":{"id":"tVMXilrYsiSZ"},"source":["**Pregunta 4 (0.5 puntos): ¬øCu√°les son las diferencias entre usar Deep learning y Machine Learning cl√°sico (empirismo) para un problema de NLP? Ejemplifique con alguna task.**"]},{"cell_type":"markdown","metadata":{"id":"_QXWMzpTtBZL"},"source":["En machine learning cl√°sico el desarrollador deb√≠a crear por el mismo las caracter√≠sticas/representaciones. En deep learning, estas representaciones son aprendidas por los mismos algoritmos."]},{"cell_type":"markdown","metadata":{"id":"6Fpsz2pQt8x5"},"source":["## **2 - Preguntas pr√°cticas üíª (4 puntos).** ##"]},{"cell_type":"markdown","metadata":{"id":"YB92kQXspvbR"},"source":["Esta segunda secci√≥n incluye ejercicios de programaci√≥n ü§ô. Leer atentamente las instrucciones entregadas a continuaci√≥n para facilitar el proceso de revisi√≥n de sus trabajos.\n"]},{"cell_type":"markdown","metadata":{"id":"PosWgWgRxHKp"},"source":["` ` \n","\n","**Instrucciones:**\n","\n","\n","\n","- Escribe tu c√≥digo entre las lineas de comentarios **### Aqu√≠ inicia tu c√≥digo ###** y **### Aqu√≠ termina tu c√≥digo ###**.\n","- Cuando el ejercicio incluya un bloque llamado ***Test***, comprueba que el resultado de la ejecuci√≥n coincida con el resultado esperado.\n","- Recuerde siempre mantener buenas pr√°cticas de c√≥digo.\n","- Est√° permitido s√≥lo utilizar las librer√≠as importadas antes del Ejercicio 1.\n","- **Recordar** que: *Documento = Oraci√≥n. Dataset = Corpus. Vocabulario = Typos*.\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"jBrmFHXhqUww"},"source":["**Ejemplo:** Implemente una funci√≥n **`hello_world()`** que imprima en pantalla `\"Hello World\"`. "]},{"cell_type":"code","metadata":{"id":"tu7cIsawyJHx"},"source":["def hello_world():\n","  ### Aqu√≠ inicia tu c√≥digo ###\n","  print(\"Hello World\")\n","  ### Aqu√≠ termina tu c√≥digo ###"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fz6klw12lwbW"},"source":["***Test:***"]},{"cell_type":"code","metadata":{"id":"ac-WMk2dyQbp","colab":{"base_uri":"https://localhost:8080/"},"outputId":"1ea259ca-3c32-4aff-f6d5-2956a8e0ec04"},"source":["hello_world()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Hello World\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"fIoiAMxtyUjQ"},"source":["***Resultado esperado***: \n","<table>\n","    <tr> \n","        <td> Hello World </td> \n","    </tr>\n","</table> \n","\n","``\n","``\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"dlPyrPXiH0l4"},"source":["Estas son las librer√≠as permitidas. Si quieren utilizar alguna librer√≠a adicional, pueden realizar la consulta a trav√©s de Discord. "]},{"cell_type":"code","metadata":{"id":"CtP6Emjo1kF0"},"source":["import codecs\n","import re\n","import numpy as np\n","import pandas as pd"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tSN4bBoY2Td4"},"source":["` ` \n","\n","**Ejercicio 1 - *Tokenizaci√≥n* (0.5 puntos).** \n","` `  \n","` ` \n","\n","En el primer ejercicio veremos la dificultad üò® de tokenizar textos no estructurados, destacando la importancia de tener librer√≠as que realicen este trabajo. \n","\n","El archivo adjunto al enunciado de la tarea contiene una interconsulta m√©dica real en Chile, estos textos son frecuentemente utilizados para obtener informaci√≥n epidemiol√≥gica y realizar estudios estad√≠sticos a partir de ellos. Es por esto que poder analizar el texto de manera correcta es fundamental. \n","\n","\n","Ejecute el c√≥digo a continuaci√≥n para cargar el ejemplo. Recuerde realizar la modificaci√≥n al directorio en caso que el archivo no se encuentre en el mismo directorio del Jupyter Notebook."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FnNUYlWo21g4","outputId":"4901bd5b-f61c-4052-c446-493940a0208f"},"source":["text = codecs.open('interconsulta.txt', 'r', 'UTF-8').read()\n","print(text)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Interconsulta n¬∞2 del mes.-05/10/2019\r\n","- ENFERMEDAD RENAL  CR√ìNICA ETAPA 3. \r\n","- Fundamento Cl√≠nico APS: PACIENTE  DE 61 A√ëOS, \tCON ANTECEDENTES DE HRTA DE LARGA DATA.ACUDE A CONTROL PSCV CON EXAMNES, DONDE DESTACA CREATININA DE 1,43,\r\n"," CON UNA VFG CALCULADA DE 53 ML/MIN/1.73M2. CON UNA CREATININA HACE MAS DE 3 MESES DE 1.34.\r\n","                   \r\n","Enfermedad renal cronica Etapa 3(SOLICITO EVALUACION DEL CASO).\r\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"UIaOYzMk3v1X"},"source":["Implementen una funci√≥n **`get_tokens()`** que reciba un texto y entregue una lista con sus tokens. Son libres de elegir la forma de tokenizar mientras no utilicen librer√≠as con tokenizadores ya implementados. Pueden utilizar la librer√≠a **re** importada para trabajar s√≠mbolos.\n"]},{"cell_type":"markdown","metadata":{"id":"5dl42-hgIhqB"},"source":["Ejemplo de uso:\n","\n","`get_tokens('Este es un ejemplo de prueba.')` \n","\n","Nos entregar√≠a:\n","\n","`['Este', 'es', 'un', 'ejemplo', 'de', 'prueba', '.']`"]},{"cell_type":"code","metadata":{"id":"IF1RcIwq4G2x"},"source":["def get_tokens(text):\n","  ### Inicio del c√≥digo ###\n","  tokens = []\n","  tokenizer = re.compile(r'([^\\W_]+|.)')\n","  for line in text.splitlines():\n","    tokens += [t for t in tokenizer.split(line) if t.strip()!='']\n","  return tokens\n","  ### F√≠n del c√≥digo ###"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KqlSpefv4_EH","colab":{"base_uri":"https://localhost:8080/"},"outputId":"32c7a866-a999-495a-d2db-b8260fef837b"},"source":["tokens = get_tokens(text)\n","tokens"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Interconsulta',\n"," 'n',\n"," '¬∞',\n"," '2',\n"," 'del',\n"," 'mes',\n"," '.',\n"," '-',\n"," '05',\n"," '/',\n"," '10',\n"," '/',\n"," '2019',\n"," '-',\n"," 'ENFERMEDAD',\n"," 'RENAL',\n"," 'CR√ìNICA',\n"," 'ETAPA',\n"," '3',\n"," '.',\n"," '-',\n"," 'Fundamento',\n"," 'Cl√≠nico',\n"," 'APS',\n"," ':',\n"," 'PACIENTE',\n"," 'DE',\n"," '61',\n"," 'A√ëOS',\n"," ',',\n"," 'CON',\n"," 'ANTECEDENTES',\n"," 'DE',\n"," 'HRTA',\n"," 'DE',\n"," 'LARGA',\n"," 'DATA',\n"," '.',\n"," 'ACUDE',\n"," 'A',\n"," 'CONTROL',\n"," 'PSCV',\n"," 'CON',\n"," 'EXAMNES',\n"," ',',\n"," 'DONDE',\n"," 'DESTACA',\n"," 'CREATININA',\n"," 'DE',\n"," '1',\n"," ',',\n"," '43',\n"," ',',\n"," 'CON',\n"," 'UNA',\n"," 'VFG',\n"," 'CALCULADA',\n"," 'DE',\n"," '53',\n"," 'ML',\n"," '/',\n"," 'MIN',\n"," '/',\n"," '1',\n"," '.',\n"," '73M2',\n"," '.',\n"," 'CON',\n"," 'UNA',\n"," 'CREATININA',\n"," 'HACE',\n"," 'MAS',\n"," 'DE',\n"," '3',\n"," 'MESES',\n"," 'DE',\n"," '1',\n"," '.',\n"," '34',\n"," '.',\n"," 'Enfermedad',\n"," 'renal',\n"," 'cronica',\n"," 'Etapa',\n"," '3',\n"," '(',\n"," 'SOLICITO',\n"," 'EVALUACION',\n"," 'DEL',\n"," 'CASO',\n"," ')',\n"," '.']"]},"metadata":{"tags":[]},"execution_count":44}]},{"cell_type":"markdown","metadata":{"id":"TPbgTvAW-stF"},"source":["**Describa cu√°les fueron sus supuestos para realizar la tokenizaci√≥n y compare sus tokens con los entregados por la librer√≠a nltk en el bloque de c√≥digo de m√°s abajo.**"]},{"cell_type":"markdown","metadata":{"id":"jGQ7CJy3-3aH"},"source":["Se utilizaron patrones de expresiones regulares para poder separar correctamente los s√≠mbolos en el texto. En este caso, el tokenizador act√∫a mejor que el de Nltk."]},{"cell_type":"code","metadata":{"id":"YYtmAXTr9KXK","colab":{"base_uri":"https://localhost:8080/","height":209},"executionInfo":{"status":"error","timestamp":1619745428573,"user_tz":420,"elapsed":2009,"user":{"displayName":"MAURICIO JES√öS ARANEDA","photoUrl":"","userId":"01648930000647588579"}},"outputId":"81cec46b-37c6-48f3-b412-4e26c8a50627"},"source":["from nltk.tokenize import wordpunct_tokenize \n","nltk_tokens = wordpunct_tokenize(text)\n","nltk_tokens"],"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-126d3f115267>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwordpunct_tokenize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnltk_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwordpunct_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mnltk_tokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'text' is not defined"]}]},{"cell_type":"markdown","metadata":{"id":"s5QKlXAZwN1L"},"source":["` `  \n","` ` \n","\n","**Ejercicio 2 - *Stopwords y Stemming* (1 punto).** \n","` `  \n","` ` \n","\n","Considere el siguiente corpus:\n"]},{"cell_type":"code","metadata":{"id":"sEp83zESwb2j"},"source":["dataset = [\"I like human languages\", \"I like programming languages\", \"Spanish is my favorite language\"]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gmjdlJWuyS2E"},"source":["Dise√±e una funci√≥n **`get_vocab()`** que extraiga los typos de este corpus solamente tokenizando. Puede utilizar la funci√≥n del Ejercicio 1."]},{"cell_type":"code","metadata":{"id":"UudC-b6TzZgw"},"source":["def get_vocab(dataset):\n","  ### Aqu√≠ inicia tu c√≥digo ###\n","  tokens = []\n","  for sent in dataset:\n","    tokens += get_tokens(sent)\n","  return list(set(tokens))\n","  ### Aqu√≠ termina tu c√≥digo ###"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5-m32IoNmSwM"},"source":["***Test:***"]},{"cell_type":"code","metadata":{"id":"BNzPKiAx0Aa1","colab":{"base_uri":"https://localhost:8080/"},"outputId":"0c58b6ea-f37e-497c-8f5d-ecce29eb17a5"},"source":["vocab = get_vocab(dataset)\n","vocab"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['favorite',\n"," 'language',\n"," 'Spanish',\n"," 'is',\n"," 'my',\n"," 'I',\n"," 'languages',\n"," 'human',\n"," 'programming',\n"," 'like']"]},"metadata":{"tags":[]},"execution_count":57}]},{"cell_type":"markdown","metadata":{"id":"qZLV2hWf9FN7"},"source":["``\n","``\n","\n","***Resultado esperado***: \n","<table>\n","    <tr> \n","        <td>['favorite',\n"," 'Spanish',\n"," 'language',\n"," 'I',\n"," 'like',\n"," 'programming',\n"," 'languages',\n"," 'my',\n"," 'human',\n"," 'is'] </td> \n","    </tr>\n","</table> \n","\n","``\n","``"]},{"cell_type":"markdown","metadata":{"id":"L3KB0fL2zk2v"},"source":["Ahora dise√±e reglas que usted estime convenientes tanto de **Stemming** como de **Stopwords**. Implemente una funci√≥n que reciba una lista con los elementos del vocabulario, le aplique sus reglas y devuelva el vocabulario actualizado. "]},{"cell_type":"markdown","metadata":{"id":"iY7g67Ml0aby"},"source":["Stopwords: I, is, my\n"," \n","Reglas de Stemming: \n"," \n","- ...s -> nada\n","- ...ing -> nada"]},{"cell_type":"code","metadata":{"id":"lrKDtM_H0XlE"},"source":["def pre_processing(vocab): \n","  ### Aqu√≠ inicia tu c√≥digo ###\n","  new_vocab = []\n","  stopwords = ['I', 'is', 'my']\n","  for word in vocab:\n","    if word not in stopwords:\n","      if word.endswith('s'):\n","        new_vocab.append(word[:-1])\n","      elif word.endswith('ing'):\n","        new_vocab.append(word[:-3])\n","      else:\n","        new_vocab.append(word)\n","  return list(set(new_vocab))\n","  ### Aqu√≠ termina tu c√≥digo ###"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"onOSuS-_mL2F","colab":{"base_uri":"https://localhost:8080/"},"outputId":"d1796c0d-9d06-4fbd-d956-195e9f78a0a4"},"source":["vocab = pre_processing(vocab)\n","vocab"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['favorite', 'language', 'Spanish', 'programm', 'human', 'like']"]},"metadata":{"tags":[]},"execution_count":59}]},{"cell_type":"markdown","metadata":{"id":"65IwHx11uA75"},"source":["` `  \n","` ` \n","\n","**Ejercicio 3 - *Bag of Words* üê∂üêà(0.5 puntos).** \n","` `  \n","` ` \n","\n","Considere el siguiente corpus, donde cada elemento del arreglo representa un documento:"]},{"cell_type":"code","metadata":{"id":"Rh-utMuozhsK"},"source":["d0 = 'El perro se come la comida y despu√©s se duerme'\n","d1 = 'El perro se despierta y despu√©s empieza a ladrar'\n","d2 = 'El perro ladra y despu√©s se come la comida'\n","d3 = 'El gato se come la comida y despu√©s se duerme'\n","d4 = 'El gato se despierta y despu√©s empieza a maullar'\n","d5 = 'El gato maulla y despu√©s se come la comida'\n","dataset = [d0, d1, d2, d3, d4, d5]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WH7ne8C6ltvE"},"source":["El objetivo de este ejercicio es determinar cu√°les de  los documentos entregados son los m√°s similares entre s√≠. Para ello utilizaremos la t√©cnica TF-IDF. \n","\n","Como los algoritmos de Machine Learning no comprenden el texto en lenguaje natural, estos documentos deben ser convertidos a vectores num√©ricos. La representaci√≥n m√°s simple vista en clases es el **Bag of Words**, m√©todo mediante el cu√°l se cuentan las apariciones de cada palabra en cada uno de los documentos entregados.\n","\n","Implemente la funci√≥n **`bag_of_words()`**, que reciba como input un arreglo de documentos y devuelva un pandas dataframe con la representaci√≥n Bag of Words de los documentos entregados. En esta representaci√≥n las columnas son el vocabulario y las filas representa las apariciones de cada una de las palabras en los documentos. En otras palabras, cada fila representa el bow de un determinado documento.\n","\n","\n","Por ejemplo para el siguiente dataset: \n","\n","```\n","dataset = ['El perro ladra', 'El perro come']\n","```\n","\n","Debiese entregarnos lo siguiente:\n","\n","\n","|   | el | perro | ladra | come |\n","|---|----|-------|------|-------|\n","| 0 | 1  | 1     | 1    | 0     |\n","| 1 | 1  | 1     | 0    | 1     |\n","\n"]},{"cell_type":"code","metadata":{"id":"kXDMAyFmnq5j"},"source":["def bag_of_words(dataset):\n","  ### Aqu√≠ inicia tu c√≥digo ###\n","  all_bow = []\n","  for document in dataset:\n","      current_bow = {word: 0 for word in get_vocab(dataset)}\n","      for word in get_tokens(document):\n","          current_bow[word] += 1\n","      all_bow.append(current_bow)\n","  return pd.DataFrame(all_bow, index = ['d0', 'd1', 'd2', 'd3', 'd4', 'd5'])\n","  ### Aqu√≠ termina tu c√≥digo ###"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"okfo-nEQmW1R"},"source":["***Test:***"]},{"cell_type":"code","metadata":{"id":"T_Kk9GwCoDW8","colab":{"base_uri":"https://localhost:8080/","height":238},"executionInfo":{"status":"ok","timestamp":1619745444837,"user_tz":420,"elapsed":343,"user":{"displayName":"MAURICIO JES√öS ARANEDA","photoUrl":"","userId":"01648930000647588579"}},"outputId":"8394bef7-4f0b-478f-e218-206041be242d"},"source":["dataset_bow = bag_of_words(dataset)\n","dataset_bow"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>maulla</th>\n","      <th>perro</th>\n","      <th>gato</th>\n","      <th>despierta</th>\n","      <th>a</th>\n","      <th>El</th>\n","      <th>despu√©s</th>\n","      <th>ladra</th>\n","      <th>ladrar</th>\n","      <th>maullar</th>\n","      <th>y</th>\n","      <th>la</th>\n","      <th>se</th>\n","      <th>empieza</th>\n","      <th>comida</th>\n","      <th>come</th>\n","      <th>duerme</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>d0</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>d1</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>d2</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>d3</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>d4</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>d5</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    maulla  perro  gato  despierta  a  ...  se  empieza  comida  come  duerme\n","d0       0      1     0          0  0  ...   2        0       1     1       1\n","d1       0      1     0          1  1  ...   1        1       0     0       0\n","d2       0      1     0          0  0  ...   1        0       1     1       0\n","d3       0      0     1          0  0  ...   2        0       1     1       1\n","d4       0      0     1          1  1  ...   1        1       0     0       0\n","d5       1      0     1          0  0  ...   1        0       1     1       0\n","\n","[6 rows x 17 columns]"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"markdown","metadata":{"id":"oeR5ADGz-MPa"},"source":["``\n","``\n","\n","***Resultado esperado***: \n","\n","|    | El | perro | se | come | la | comida | y | despu√©s | duerme | despierta | empieza | a | ladrar | ladra | gato | maullar | maulla |\n","|----|---:|------:|---:|-----:|---:|-------:|--:|--------:|-------:|----------:|--------:|--:|-------:|------:|-----:|--------:|-------:|\n","| d0 |  1 |     1 |  2 |    1 |  1 |      1 | 1 |       1 |      1 |         0 |       0 | 0 |      0 |     0 |    0 |       0 |      0 |\n","| d1 |  1 |     1 |  1 |    0 |  0 |      0 | 1 |       1 |      0 |         1 |       1 | 1 |      1 |     0 |    0 |       0 |      0 |\n","| d2 |  1 |     1 |  1 |    1 |  1 |      1 | 1 |       1 |      0 |         0 |       0 | 0 |      0 |     1 |    0 |       0 |      0 |\n","| d3 |  1 |     0 |  2 |    1 |  1 |      1 | 1 |       1 |      1 |         0 |       0 | 0 |      0 |     0 |    1 |       0 |      0 |\n","| d4 |  1 |     0 |  1 |    0 |  0 |      0 | 1 |       1 |      0 |         1 |       1 | 1 |      0 |     0 |    1 |       1 |      0 |\n","| d5 |  1 |     0 |  1 |    1 |  1 |      1 | 1 |       1 |      0 |         0 |       0 | 0 |      0 |     0 |    1 |       0 |      1 |\n","\n","``\n","``"]},{"cell_type":"markdown","metadata":{"id":"K4OXMz7opWcd"},"source":["` `  \n","` ` \n","\n","**Ejercicio 4 - *Calcular TF* (0.5 puntos):** Ahora debemos usar el dataframe del ejercicio anterior para calcular la matriz de TF normalizada por la m√°xima frecuencia ${max_i({\\text{tf}_{i,j})}}$, donde\n","i corresponde al √≠ndice de las filas (bow) y j al de las columnas (palabras). Es decir, dividir cada bow en la cantidad de veces de la palabra que aparezca m√°s veces en ese vector (documento). \n","\n","\n","$$\\text{nft}_{i,j} = \\frac{\\text{tf}_{i,j}}{max_i({\\text{tf}_{i,j})}}$$"]},{"cell_type":"code","metadata":{"id":"xWE16xhBpswc"},"source":["def calc_tf(dataset_bow):\n","    ### Aqu√≠ inicia tu c√≥digo ###\n","    return dataset_bow.divide(dataset_bow.max(axis=1), axis=0)\n","    ### Aqu√≠ termina tu c√≥digo ###"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AZQPZe3JmYqy"},"source":["***Test:***"]},{"cell_type":"code","metadata":{"id":"YQ2h8jEYp4nZ","colab":{"base_uri":"https://localhost:8080/","height":238},"executionInfo":{"status":"ok","timestamp":1619745449216,"user_tz":420,"elapsed":337,"user":{"displayName":"MAURICIO JES√öS ARANEDA","photoUrl":"","userId":"01648930000647588579"}},"outputId":"6b14962b-a936-45f6-8fcd-1c65afddf976"},"source":["tf = calc_tf(dataset_bow)\n","tf"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>maulla</th>\n","      <th>perro</th>\n","      <th>gato</th>\n","      <th>despierta</th>\n","      <th>a</th>\n","      <th>El</th>\n","      <th>despu√©s</th>\n","      <th>ladra</th>\n","      <th>ladrar</th>\n","      <th>maullar</th>\n","      <th>y</th>\n","      <th>la</th>\n","      <th>se</th>\n","      <th>empieza</th>\n","      <th>comida</th>\n","      <th>come</th>\n","      <th>duerme</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>d0</th>\n","      <td>0.0</td>\n","      <td>0.5</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.5</td>\n","      <td>0.5</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.5</td>\n","      <td>0.5</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.5</td>\n","      <td>0.5</td>\n","      <td>0.5</td>\n","    </tr>\n","    <tr>\n","      <th>d1</th>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>d2</th>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>d3</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.5</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.5</td>\n","      <td>0.5</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.5</td>\n","      <td>0.5</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.5</td>\n","      <td>0.5</td>\n","      <td>0.5</td>\n","    </tr>\n","    <tr>\n","      <th>d4</th>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>d5</th>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    maulla  perro  gato  despierta    a  ...   se  empieza  comida  come  duerme\n","d0     0.0    0.5   0.0        0.0  0.0  ...  1.0      0.0     0.5   0.5     0.5\n","d1     0.0    1.0   0.0        1.0  1.0  ...  1.0      1.0     0.0   0.0     0.0\n","d2     0.0    1.0   0.0        0.0  0.0  ...  1.0      0.0     1.0   1.0     0.0\n","d3     0.0    0.0   0.5        0.0  0.0  ...  1.0      0.0     0.5   0.5     0.5\n","d4     0.0    0.0   1.0        1.0  1.0  ...  1.0      1.0     0.0   0.0     0.0\n","d5     1.0    0.0   1.0        0.0  0.0  ...  1.0      0.0     1.0   1.0     0.0\n","\n","[6 rows x 17 columns]"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"markdown","metadata":{"id":"TOzdRwx9_UMM"},"source":["``\n","``\n","\n","***Resultado esperado***: \n","\n","|    |  El | perro |  se | come |  la | comida |   y | despu√©s | duerme | despierta | empieza |   a | ladrar | ladra | gato | maullar | maulla |\n","|----|----:|------:|----:|-----:|----:|-------:|----:|--------:|-------:|----------:|--------:|----:|-------:|------:|-----:|--------:|-------:|\n","| d0 | 0.5 |   0.5 | 1.0 |  0.5 | 0.5 |    0.5 | 0.5 |     0.5 |    0.5 |       0.0 |     0.0 | 0.0 |    0.0 |   0.0 |  0.0 |     0.0 |    0.0 |\n","| d1 | 1.0 |   1.0 | 1.0 |  0.0 | 0.0 |    0.0 | 1.0 |     1.0 |    0.0 |       1.0 |     1.0 | 1.0 |    1.0 |   0.0 |  0.0 |     0.0 |    0.0 |\n","| d2 | 1.0 |   1.0 | 1.0 |  1.0 | 1.0 |    1.0 | 1.0 |     1.0 |    0.0 |       0.0 |     0.0 | 0.0 |    0.0 |   1.0 |  0.0 |     0.0 |    0.0 |\n","| d3 | 0.5 |   0.0 | 1.0 |  0.5 | 0.5 |    0.5 | 0.5 |     0.5 |    0.5 |       0.0 |     0.0 | 0.0 |    0.0 |   0.0 |  0.5 |     0.0 |    0.0 |\n","| d4 | 1.0 |   0.0 | 1.0 |  0.0 | 0.0 |    0.0 | 1.0 |     1.0 |    0.0 |       1.0 |     1.0 | 1.0 |    0.0 |   0.0 |  1.0 |     1.0 |    0.0 |\n","| d5 | 1.0 |   0.0 | 1.0 |  1.0 | 1.0 |    1.0 | 1.0 |     1.0 |    0.0 |       0.0 |     0.0 | 0.0 |    0.0 |   0.0 |  1.0 |     0.0 |    1.0 |\n","\n","``\n","``"]},{"cell_type":"markdown","metadata":{"id":"ZqgW4Ni4t0xC"},"source":["` `  \n","` ` \n","\n","**Ejercicio 5 - *Calcular IDF* (0.5 punto):**\n","\n","\n","Implementar `calc_idf(dataset_bow)`. Este debe retornar un diccionario en donde las llaves sean las palabras y los valores sean el calculo de cada idf por palabra.\n","\n","Recordar que $idf_{t_i} = log_{10}\\frac{N}{n_i}$ con $N = $ n√∫mero de documentos y $n_i = $ N√∫mero de documentos que contienen la palabra $t_i$ "]},{"cell_type":"code","metadata":{"id":"thhDY1-Ht6T5"},"source":["def calc_idf(dataset_bow):\n","    ### Aqu√≠ inicia tu c√≥digo ###\n","    number_of_docs = len(dataset_bow)\n","    idf = {}\n","    for word in dataset_bow:\n","        n_i = (dataset_bow[[word]] != 0).sum()[0]\n","        idf[word] = np.log10(number_of_docs/n_i)\n","    return idf\n","    ### Aqu√≠ termina tu c√≥digo ###"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yR_j3pYemcAc"},"source":["***Test:***"]},{"cell_type":"code","metadata":{"id":"ro-OMGpduC0R","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619745452781,"user_tz":420,"elapsed":325,"user":{"displayName":"MAURICIO JES√öS ARANEDA","photoUrl":"","userId":"01648930000647588579"}},"outputId":"35bfe7c2-b458-47c2-ccd7-7ce6d9ceacb5"},"source":["idf = calc_idf(dataset_bow)\n","idf"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'El': 0.0,\n"," 'a': 0.47712125471966244,\n"," 'come': 0.17609125905568124,\n"," 'comida': 0.17609125905568124,\n"," 'despierta': 0.47712125471966244,\n"," 'despu√©s': 0.0,\n"," 'duerme': 0.47712125471966244,\n"," 'empieza': 0.47712125471966244,\n"," 'gato': 0.3010299956639812,\n"," 'la': 0.17609125905568124,\n"," 'ladra': 0.7781512503836436,\n"," 'ladrar': 0.7781512503836436,\n"," 'maulla': 0.7781512503836436,\n"," 'maullar': 0.7781512503836436,\n"," 'perro': 0.3010299956639812,\n"," 'se': 0.0,\n"," 'y': 0.0}"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"markdown","metadata":{"id":"TwjMAUUJ_i17"},"source":["``\n","``\n","\n","***Resultado esperado***: \n","<table>\n","    <tr> \n","        <td> {'El': 0.0,\n"," 'a': 0.47712125471966244,\n"," 'come': 0.17609125905568124,\n"," 'comida': 0.17609125905568124,\n"," 'despierta': 0.47712125471966244,\n"," 'despu√©s': 0.0,\n"," 'duerme': 0.47712125471966244,\n"," 'empieza': 0.47712125471966244,\n"," 'gato': 0.3010299956639812,\n"," 'la': 0.17609125905568124,\n"," 'ladra': 0.7781512503836436,\n"," 'ladrar': 0.7781512503836436,\n"," 'maulla': 0.7781512503836436,\n"," 'maullar': 0.7781512503836436,\n"," 'perro': 0.3010299956639812,\n"," 'se': 0.0,\n"," 'y': 0.0} </td> \n","    </tr>\n","</table> \n","\n","``\n","``"]},{"cell_type":"markdown","metadata":{"id":"IzKAzJtSJ7gx"},"source":["Puede notar el bajo puntaje otorgado a las palabras que m√°s se repiten! üòÆ"]},{"cell_type":"markdown","metadata":{"id":"D17lm6l9uJPo"},"source":["**Ejercicio 6 - *Calcular TF-IDF & concluir similitud de documentos.* (1 punto)**\n"]},{"cell_type":"markdown","metadata":{"id":"bc7FTQ19Kcwo"},"source":["Programe la funci√≥n `calc_tf_idf(tf, idf)` que entrega el dataframe TF-IDF asociado al dataset que estamos analizando."]},{"cell_type":"code","metadata":{"id":"9knMl0KguMwo"},"source":["def calc_tf_idf(tf, idf):\n","    ### Aqu√≠ inicia tu c√≥digo ###\n","    return tf * idf\n","    ### Aqu√≠ termina tu c√≥digo ### "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tRzIr1nQmepp"},"source":["***Test.***"]},{"cell_type":"code","metadata":{"id":"H8z6jaq2uPEo","colab":{"base_uri":"https://localhost:8080/","height":238},"executionInfo":{"status":"ok","timestamp":1619745456932,"user_tz":420,"elapsed":322,"user":{"displayName":"MAURICIO JES√öS ARANEDA","photoUrl":"","userId":"01648930000647588579"}},"outputId":"fa9b6296-d4b4-47cd-b906-085b9a889e5f"},"source":["tf_idf = calc_tf_idf(tf, idf)\n","tf_idf"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>maulla</th>\n","      <th>perro</th>\n","      <th>gato</th>\n","      <th>despierta</th>\n","      <th>a</th>\n","      <th>El</th>\n","      <th>despu√©s</th>\n","      <th>ladra</th>\n","      <th>ladrar</th>\n","      <th>maullar</th>\n","      <th>y</th>\n","      <th>la</th>\n","      <th>se</th>\n","      <th>empieza</th>\n","      <th>comida</th>\n","      <th>come</th>\n","      <th>duerme</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>d0</th>\n","      <td>0.000000</td>\n","      <td>0.150515</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.088046</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.088046</td>\n","      <td>0.088046</td>\n","      <td>0.238561</td>\n","    </tr>\n","    <tr>\n","      <th>d1</th>\n","      <td>0.000000</td>\n","      <td>0.301030</td>\n","      <td>0.000000</td>\n","      <td>0.477121</td>\n","      <td>0.477121</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.778151</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.477121</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>d2</th>\n","      <td>0.000000</td>\n","      <td>0.301030</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.778151</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.176091</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.176091</td>\n","      <td>0.176091</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>d3</th>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.150515</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.088046</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.088046</td>\n","      <td>0.088046</td>\n","      <td>0.238561</td>\n","    </tr>\n","    <tr>\n","      <th>d4</th>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.301030</td>\n","      <td>0.477121</td>\n","      <td>0.477121</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.778151</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.477121</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>d5</th>\n","      <td>0.778151</td>\n","      <td>0.000000</td>\n","      <td>0.301030</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.176091</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","      <td>0.176091</td>\n","      <td>0.176091</td>\n","      <td>0.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      maulla     perro      gato  ...    comida      come    duerme\n","d0  0.000000  0.150515  0.000000  ...  0.088046  0.088046  0.238561\n","d1  0.000000  0.301030  0.000000  ...  0.000000  0.000000  0.000000\n","d2  0.000000  0.301030  0.000000  ...  0.176091  0.176091  0.000000\n","d3  0.000000  0.000000  0.150515  ...  0.088046  0.088046  0.238561\n","d4  0.000000  0.000000  0.301030  ...  0.000000  0.000000  0.000000\n","d5  0.778151  0.000000  0.301030  ...  0.176091  0.176091  0.000000\n","\n","[6 rows x 17 columns]"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"markdown","metadata":{"id":"ZBG2qfwv_6HK"},"source":["``\n","``\n","\n","***Resultado esperado***: \n","\n","|    |  El |    perro |  se |     come |       la |   comida |   y | despu√©s |   duerme | despierta |  empieza |        a |   ladrar |    ladra |     gato |  maullar |   maulla |\n","|----|----:|---------:|----:|---------:|---------:|---------:|----:|--------:|---------:|----------:|---------:|---------:|---------:|---------:|---------:|---------:|---------:|\n","| d0 | 0.0 | 0.150515 | 0.0 | 0.088046 | 0.088046 | 0.088046 | 0.0 |     0.0 | 0.238561 |  0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 |\n","| d1 | 0.0 | 0.301030 | 0.0 | 0.000000 | 0.000000 | 0.000000 | 0.0 |     0.0 | 0.000000 |  0.477121 | 0.477121 | 0.477121 | 0.778151 | 0.000000 | 0.000000 | 0.000000 | 0.000000 |\n","| d2 | 0.0 | 0.301030 | 0.0 | 0.176091 | 0.176091 | 0.176091 | 0.0 |     0.0 | 0.000000 |  0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.778151 | 0.000000 | 0.000000 | 0.000000 |\n","| d3 | 0.0 | 0.000000 | 0.0 | 0.088046 | 0.088046 | 0.088046 | 0.0 |     0.0 | 0.238561 |  0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.150515 | 0.000000 | 0.000000 |\n","| d4 | 0.0 | 0.000000 | 0.0 | 0.000000 | 0.000000 | 0.000000 | 0.0 |     0.0 | 0.000000 |  0.477121 | 0.477121 | 0.477121 | 0.000000 | 0.000000 | 0.301030 | 0.778151 | 0.000000 |\n","| d5 | 0.0 | 0.000000 | 0.0 | 0.176091 | 0.176091 | 0.176091 | 0.0 |     0.0 | 0.000000 |  0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.000000 | 0.301030 | 0.000000 | 0.778151 |\n","\n","\n","``\n","``"]},{"cell_type":"markdown","metadata":{"id":"WmVlbpzMp5NU"},"source":["Ahora que tenemos el dataframe de TF-IDF, nos queda calcular la similitud coseno entre todos los vectores. Notar que la matriz resultante ser√° una matriz sim√©trica. Implemente la funci√≥n *cosine_similarity(v1, v2)* que recibe dos vectores (v1 y v2) y calcula la similitud coseno entre ambos vectores. Concluya cu√°les son los dos documentos m√°s similares."]},{"cell_type":"code","metadata":{"id":"HEgUtgBkQAae","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619745458541,"user_tz":420,"elapsed":363,"user":{"displayName":"MAURICIO JES√öS ARANEDA","photoUrl":"","userId":"01648930000647588579"}},"outputId":"245aec66-4ffb-45e6-a6d6-747e39eb5336"},"source":["def cosine_similarity(v1, v2):\n","  ### Aqu√≠ inicia tu c√≥digo ###\n","  return np.dot(v1,v2)/(np.linalg.norm(v1)*np.linalg.norm(v2))\n","  ### Aqu√≠ termina tu c√≥digo ### \n","\n","similarity_matrix = np.zeros((6,6))\n","for i, v1 in enumerate(tf_idf.index.values):\n","  for j, v2 in enumerate(tf_idf.index.values):\n","      similarity = cosine_similarity(tf_idf.loc[v1].values, tf_idf.loc[v2].values)\n","      similarity_matrix[i][j] = similarity\n","      \n","print(similarity_matrix)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[[1.         0.12032418 0.3223436  0.77967014 0.         0.1632828 ]\n"," [0.12032418 1.         0.08686457 0.         0.4952126  0.        ]\n"," [0.3223436  0.08686457 1.         0.1632828  0.         0.11787732]\n"," [0.77967014 0.         0.1632828  1.         0.12032418 0.3223436 ]\n"," [0.         0.4952126  0.         0.12032418 1.         0.08686457]\n"," [0.1632828  0.         0.11787732 0.3223436  0.08686457 1.        ]]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"u9FlltqIqRxf"},"source":["Como era de esperar, con la t√©cnica TF-IDF los documentos m√°s similares son los documentos d0 y d3, ya que difieren en una sola palabra entre muchas. Ahora bien, sabemos que esas dos palabras son muy diferentes entre s√≠ (perro y gato) pero este algoritmo no puede capturar dicha interpretaci√≥n ya que se basa en t√©cnicas de frecuencias y no de contexto, para ello utilizaremos pronto los Word Embeddings!"]},{"cell_type":"markdown","metadata":{"id":"FUAc1zX0Lg16"},"source":["![gato](https://www.elagoradiario.com/wp-content/uploads/2020/05/Gato-mascarilla.jpg)"]},{"cell_type":"markdown","metadata":{"id":"s1A95IaXLHaB"},"source":["**Cualquier recomendaci√≥n que nos quisieran dar para una futura tarea es bienvenid@!**"]}]}