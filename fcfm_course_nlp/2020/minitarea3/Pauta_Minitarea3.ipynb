{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Pauta_Minitarea3.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9"}},"cells":[{"cell_type":"markdown","metadata":{"ExecuteTime":{"end_time":"2020-03-19T18:30:18.109327Z","start_time":"2020-03-19T18:30:18.103344Z"},"id":"q5CSRY4oNCHK"},"source":["\n","# Minitarea 3\n","\n","\n","-----------------\n","\n","Nombre: \n","\n","Fecha de Entrega: Domingo 17 de Mayo\n","\n","\n","## Instrucciones\n","\n","- El ejercicio consiste en:\n","\n","    - Responder preguntas relativas a los contenidos vistos en los vídeos y slides de las clases. \n","    \n","    - Entrenar Word2Vec y FastText sobre un pequeño corpus.\n","    \n","    - Evaluar los embeddings obtenidos en una tarea de clasificación.\n","\n","- La minitarea es INDIVIDUAL.\n","\n","- Está demás decir que no se admiten copias, ni de código, ni de respuestas escritas. \n","\n","- La entrega debe ser por u-cursos.\n","\n","- Atrasos: se descontará un punto por día hábil de atraso tanto para las mini-tareas como para las competencias.\n","\n","- En el horario de auxiliar se abrirán horarios de consulta en donde podrán preguntar acerca del ejercicio y en general, de todo el curso. \n","\n","- Cada sección tiene un punto base y se evalúa sobre 6 puntos.\n","\n","- Al revisar, tu código será ejecutado. Verifica que tu entrega no tenga errores.\n","\n","\n","## Referencias   \n","\n","Vídeos: \n","\n","- [Linear Models](https://youtu.be/zhBxDsNLZEA)\n","- [Neural Networks](https://youtu.be/oHZHA8h2xN0)\n","- [Word Embeddings](https://youtu.be/wtwUsJMC9CA)"]},{"cell_type":"markdown","metadata":{"id":"G4wYf0vgnbTv"},"source":["## Preguntas Teóricas\n","Para estas preguntas no es necesario implementar código, pero pueden utilizar pseudo código."]},{"cell_type":"markdown","metadata":{"id":"B5hUG6-8ngoK"},"source":["### Parte 1: Modelos Lineales"]},{"cell_type":"markdown","metadata":{"id":"5yRvZbhsoi8f"},"source":["Suponga que tiene un dataset de 10.000 documentos etiquetados por 4 categorías: política, deporte, negocios y otros. "]},{"cell_type":"markdown","metadata":{"id":"irsqBVmCnx3M"},"source":["**Pregunta 1**: Diseñe un modelo lineal capaz de clasificar un documento según estas categorías donde el output sea un vector con una distribución de probabilidad con la pertenencia a cada clase. (3 puntos)\n","\n","**Respuesta**: \n","Representación escogida del documento de entrada: Bag of words por ejemplo\n","\n","Parámetros del modelo: Matriz de pesos W en donde la columna 1 tengan mayor importancia las palabras de política, columna 2 sobre deporte, columna 3 sobre negocios y columna 4 el resto\n","\n","Transformaciones necesarias: Aplicar softmax al vector de output del modelo.\n","\n","Función de pérdida escogida: Cross-entropy es el ideal, pero pueden escoger cualquier función de perdida multiclase que alcanze el mínimo cuando las predicciones son correctas"]},{"cell_type":"markdown","metadata":{"id":"G5FaWqBVvL90"},"source":["**Pregunta 2**: Explique el proceso de entrenamiento y evaluación del modelo. (3 puntos)\n","\n","**Respuesta**: El objetivo del entrenamiento es minimizar la loss del modelo. Se van tuneando los parámetros de la matriz W hasta encontrar uno que minimice la loss del modelo."]},{"cell_type":"markdown","metadata":{"id":"XkK7pc54njZq"},"source":["### Parte 2: Redes Neuronales"]},{"cell_type":"markdown","metadata":{"id":"VUbJjlj_9AFC"},"source":["Supongamos que tenemos la siguiente red neuronal."]},{"cell_type":"markdown","metadata":{"id":"obUfuOYB_TOC"},"source":["![image.png](attachment:image.png)"]},{"cell_type":"markdown","metadata":{"id":"s2z-8zKW0_6q"},"source":["**Pregunta 1**: En clases les explicaron como se puede representar una red neuronal de una y dos capas de manera matemática. Dada la red neuronal anterior, represéntela matemáticamente, entregando las dimensiones de las matrices y vectores. (3 Puntos)\n","\n","**Respuesta**: \n","\n","Formula:\n","$\\vec{\\hat{y}} = NN_{MLP3}(\\vec{x})= h(f(g(\\vec{x}W¹+\\vec{b}¹)W²+\\vec{b}²)W³+\\vec{b}³)W⁴+\\vec{b}⁴$ (1 punto)\n","\n","Dimensiones: (2 puntos)\n","- $\\vec{x}$: 3\n","- $W¹$: 3x2\n","- $\\vec{b}¹$: 2\n","- $W²$: 2x3\n","- $\\vec{b}²$: 3\n","- $W³:$ 3x1\n","- $\\vec{b}³:$ 1\n","- $W⁴:$ 1x4\n","- $\\vec{b}⁴:$ 4\n","\n","**Pregunta 2**: Qué es backpropagation? Cuales serían los parámetros a evaluar en la red neuronal anterior? (1 punto)\n","\n","**Respuesta**: \"Backpropagation es una técnica eficiente para evaluar el gradiente de una loss function L en una red neuronal feed-forward con respecto a todos sus parámetros\" (Cita de clases). Los parámetros serian de $W¹,\\vec{b}¹$ a $W⁴,\\vec{b}⁴$\n","\n","**Pregunta 3**: Explique los pasos de backpropagation. En la red neuronal anterior: Cuales son las derivadas que debemos calcular para poder obtener $\\vec{\\delta^l_{[j]}}$ en todas las capas? (2 puntos)\n","\n","**Respuesta**: Los 4 pasos son:\n","\n","- Aplicar el vector x y propagarlo por toda la red\n","- Evaluar $\\delta$ para todas las unidades ocultas\n","- Propagar los $\\delta$ desde el final al inicio de la red\n","- Ocupar la formula de $\\frac{\\partial L}{\\partial W}$\n","\n","En la red anterior se necesitan las derivadas: $f', g',h'$"]},{"cell_type":"markdown","metadata":{"id":"ocS_vQhR1gcU"},"source":["## Pregunta Práctica:"]},{"cell_type":"markdown","metadata":{"id":"Ol82nJ0FnmcP"},"source":["### Parte 3: Word Embeddings"]},{"cell_type":"markdown","metadata":{"id":"OgmeSFqKLpFL"},"source":["En la auxiliar 2 aprendieron como entrenar Word2Vec utilizando gensim. El objetivo de esta parte es comparar los embeddings obtenidos con dos modelos diferentes: Word2Vec y [FastText](https://radimrehurek.com/gensim/models/fasttext.html) (utilizen size=200 en FastText) entrenados en el mismo dataset de diálogos de los Simpson. "]},{"cell_type":"code","metadata":{"id":"ecCvnryeQiG7","executionInfo":{"status":"ok","timestamp":1620239306616,"user_tz":420,"elapsed":1775,"user":{"displayName":"MAURICIO JESÚS ARANEDA","photoUrl":"","userId":"01648930000647588579"}}},"source":["import re  \n","import pandas as pd \n","from time import time  \n","from collections import defaultdict \n","import string \n","import multiprocessing\n","import os\n","import gensim\n","import sklearn\n","from sklearn import linear_model\n","from collections import Counter\n","import numpy as np\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, cohen_kappa_score, classification_report\n","\n","# word2vec\n","from gensim.models import Word2Vec, KeyedVectors, FastText\n","from gensim.models.phrases import Phrases, Phraser\n","from sklearn.model_selection import train_test_split\n","import logging\n","\n","logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n","logger = logging.getLogger(__name__)"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tZgN06q4QPi3"},"source":["Utilizando el dataset adjunto con la tarea:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eY3kmg4onnsu","executionInfo":{"status":"ok","timestamp":1620239307260,"user_tz":420,"elapsed":833,"user":{"displayName":"MAURICIO JESÚS ARANEDA","photoUrl":"","userId":"01648930000647588579"}},"outputId":"7f05ea7f-01b9-4608-d549-8968ad7dab79"},"source":["data_file = \"dialogue-lines-of-the-simpsons.zip\"\n","df = pd.read_csv(data_file)\n","stopwords = pd.read_csv(\n","    'https://raw.githubusercontent.com/Alir3z4/stop-words/master/english.txt'\n",").values\n","stopwords = Counter(stopwords.flatten().tolist())\n","df = df.dropna().reset_index(drop=True) # Quitar filas vacias"],"execution_count":2,"outputs":[{"output_type":"stream","text":["2021-05-05 18:27:47,264 : INFO : NumExpr defaulting to 2 threads.\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"VAg5a5bmWk3T"},"source":["**Pregunta 1**: Ayudándose de los pasos vistos en la auxiliar, entrene los modelos Word2Vec y FastText sobre el dataset anterior. (4 puntos) (Hint, le puede servir explorar un poco los datos)"]},{"cell_type":"markdown","metadata":{"id":"MWw2fXFRXe5Y"},"source":["Respuesta:"]},{"cell_type":"code","metadata":{"id":"-xW6KcHtXckz","executionInfo":{"status":"ok","timestamp":1620239310133,"user_tz":420,"elapsed":1531,"user":{"displayName":"MAURICIO JESÚS ARANEDA","photoUrl":"","userId":"01648930000647588579"}}},"source":["punctuation = string.punctuation + \"«»“”‘’…—\"\n","def simple_tokenizer(doc, lower=False):\n","    if lower:\n","        tokenized_doc = doc.translate(str.maketrans(\n","            '', '', punctuation)).lower().split()\n","\n","    tokenized_doc = doc.translate(str.maketrans('', '', punctuation)).split()\n","\n","    tokenized_doc = [\n","        token for token in tokenized_doc if token.lower() not in stopwords\n","    ]\n","    return tokenized_doc\n","content = df['spoken_words']\n","cleaned_content = [simple_tokenizer(doc) for doc in content.values]"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HjftVgdrT96m","executionInfo":{"status":"ok","timestamp":1620239349866,"user_tz":420,"elapsed":4504,"user":{"displayName":"MAURICIO JESÚS ARANEDA","photoUrl":"","userId":"01648930000647588579"}},"outputId":"dd6f2095-397c-4f17-9217-a2108fc7e6a0"},"source":["phrases = Phrases(cleaned_content, min_count=100, progress_per=5000)\n","bigram = Phraser(phrases)\n","sentences = bigram[cleaned_content]"],"execution_count":8,"outputs":[{"output_type":"stream","text":["2021-05-05 18:28:25,678 : INFO : collecting all words and their counts\n","2021-05-05 18:28:25,681 : INFO : PROGRESS: at sentence #0, processed 0 words and 0 word types\n","2021-05-05 18:28:25,724 : INFO : PROGRESS: at sentence #5000, processed 16897 words and 17696 word types\n","2021-05-05 18:28:25,763 : INFO : PROGRESS: at sentence #10000, processed 33320 words and 32774 word types\n","2021-05-05 18:28:25,800 : INFO : PROGRESS: at sentence #15000, processed 49225 words and 46074 word types\n","2021-05-05 18:28:25,842 : INFO : PROGRESS: at sentence #20000, processed 67371 words and 61074 word types\n","2021-05-05 18:28:25,886 : INFO : PROGRESS: at sentence #25000, processed 85568 words and 75938 word types\n","2021-05-05 18:28:25,931 : INFO : PROGRESS: at sentence #30000, processed 104569 words and 91367 word types\n","2021-05-05 18:28:25,976 : INFO : PROGRESS: at sentence #35000, processed 122041 words and 104739 word types\n","2021-05-05 18:28:26,020 : INFO : PROGRESS: at sentence #40000, processed 138266 words and 116598 word types\n","2021-05-05 18:28:26,061 : INFO : PROGRESS: at sentence #45000, processed 154513 words and 128541 word types\n","2021-05-05 18:28:26,103 : INFO : PROGRESS: at sentence #50000, processed 170239 words and 140055 word types\n","2021-05-05 18:28:26,143 : INFO : PROGRESS: at sentence #55000, processed 185556 words and 150956 word types\n","2021-05-05 18:28:26,175 : INFO : PROGRESS: at sentence #60000, processed 200105 words and 160956 word types\n","2021-05-05 18:28:26,211 : INFO : PROGRESS: at sentence #65000, processed 215762 words and 171680 word types\n","2021-05-05 18:28:26,272 : INFO : PROGRESS: at sentence #70000, processed 233512 words and 184773 word types\n","2021-05-05 18:28:26,315 : INFO : PROGRESS: at sentence #75000, processed 251146 words and 197413 word types\n","2021-05-05 18:28:26,363 : INFO : PROGRESS: at sentence #80000, processed 268907 words and 209846 word types\n","2021-05-05 18:28:26,413 : INFO : PROGRESS: at sentence #85000, processed 286451 words and 222075 word types\n","2021-05-05 18:28:26,455 : INFO : PROGRESS: at sentence #90000, processed 303348 words and 233815 word types\n","2021-05-05 18:28:26,494 : INFO : PROGRESS: at sentence #95000, processed 320181 words and 245355 word types\n","2021-05-05 18:28:26,540 : INFO : PROGRESS: at sentence #100000, processed 337260 words and 257141 word types\n","2021-05-05 18:28:26,583 : INFO : PROGRESS: at sentence #105000, processed 354342 words and 268926 word types\n","2021-05-05 18:28:26,626 : INFO : PROGRESS: at sentence #110000, processed 371777 words and 281027 word types\n","2021-05-05 18:28:26,672 : INFO : PROGRESS: at sentence #115000, processed 388303 words and 292112 word types\n","2021-05-05 18:28:26,720 : INFO : PROGRESS: at sentence #120000, processed 405287 words and 303526 word types\n","2021-05-05 18:28:26,763 : INFO : PROGRESS: at sentence #125000, processed 421730 words and 314026 word types\n","2021-05-05 18:28:26,808 : INFO : PROGRESS: at sentence #130000, processed 438262 words and 323837 word types\n","2021-05-05 18:28:26,826 : INFO : collected 327493 word types from a corpus of 444264 words (unigram + bigrams) and 131853 sentences\n","2021-05-05 18:28:26,831 : INFO : using 327493 counts as vocab in Phrases<0 vocab, min_count=100, threshold=10.0, max_vocab_size=40000000>\n","2021-05-05 18:28:26,833 : INFO : source_vocab length 327493\n","2021-05-05 18:28:29,866 : INFO : Phraser built with 11 phrasegrams\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"zd1CkXa7T96o","executionInfo":{"status":"ok","timestamp":1620239350296,"user_tz":420,"elapsed":423,"user":{"displayName":"MAURICIO JESÚS ARANEDA","photoUrl":"","userId":"01648930000647588579"}}},"source":["w2v_model = Word2Vec(min_count=10,\n","                      window=4,\n","                      size=200,\n","                      sample=6e-5,\n","                      alpha=0.03,\n","                      min_alpha=0.0007,\n","                      negative=20,\n","                      workers=multiprocessing.cpu_count())\n","ft_model = FastText(size=200, window=3, min_count=1)"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IfPhmZoxT96o","executionInfo":{"status":"ok","timestamp":1620239376443,"user_tz":420,"elapsed":24287,"user":{"displayName":"MAURICIO JESÚS ARANEDA","photoUrl":"","userId":"01648930000647588579"}},"outputId":"10823c00-21d8-4b7b-be12-2ff2c13d7b35"},"source":["w2v_model.build_vocab(sentences, progress_per=10000)\n","ft_model.build_vocab(sentences, progress_per=10000)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["2021-05-05 18:28:32,468 : INFO : collecting all words and their counts\n","2021-05-05 18:28:32,474 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n","2021-05-05 18:28:32,622 : INFO : PROGRESS: at sentence #10000, processed 33138 words, keeping 10665 word types\n","2021-05-05 18:28:32,775 : INFO : PROGRESS: at sentence #20000, processed 66935 words, keeping 17139 word types\n","2021-05-05 18:28:32,940 : INFO : PROGRESS: at sentence #30000, processed 103943 words, keeping 23072 word types\n","2021-05-05 18:28:33,106 : INFO : PROGRESS: at sentence #40000, processed 137471 words, keeping 27257 word types\n","2021-05-05 18:28:33,260 : INFO : PROGRESS: at sentence #50000, processed 169305 words, keeping 31180 word types\n","2021-05-05 18:28:33,411 : INFO : PROGRESS: at sentence #60000, processed 199034 words, keeping 34584 word types\n","2021-05-05 18:28:33,568 : INFO : PROGRESS: at sentence #70000, processed 232290 words, keeping 38239 word types\n","2021-05-05 18:28:33,730 : INFO : PROGRESS: at sentence #80000, processed 267551 words, keeping 41818 word types\n","2021-05-05 18:28:33,897 : INFO : PROGRESS: at sentence #90000, processed 301884 words, keeping 45072 word types\n","2021-05-05 18:28:34,054 : INFO : PROGRESS: at sentence #100000, processed 335694 words, keeping 48066 word types\n","2021-05-05 18:28:34,210 : INFO : PROGRESS: at sentence #110000, processed 370099 words, keeping 51338 word types\n","2021-05-05 18:28:34,371 : INFO : PROGRESS: at sentence #120000, processed 403504 words, keeping 54166 word types\n","2021-05-05 18:28:34,528 : INFO : PROGRESS: at sentence #130000, processed 436305 words, keeping 56287 word types\n","2021-05-05 18:28:34,558 : INFO : collected 56639 word types from a corpus of 442276 raw words and 131853 sentences\n","2021-05-05 18:28:34,560 : INFO : Loading a fresh vocabulary\n","2021-05-05 18:28:34,601 : INFO : effective_min_count=10 retains 6503 unique words (11% of original 56639, drops 50136)\n","2021-05-05 18:28:34,603 : INFO : effective_min_count=10 leaves 337000 word corpus (76% of original 442276, drops 105276)\n","2021-05-05 18:28:34,630 : INFO : deleting the raw counts dictionary of 56639 items\n","2021-05-05 18:28:34,633 : INFO : sample=6e-05 downsamples 1282 most-common words\n","2021-05-05 18:28:34,636 : INFO : downsampling leaves estimated 203191 word corpus (60.3% of prior 337000)\n","2021-05-05 18:28:34,661 : INFO : estimated required memory for 6503 words and 200 dimensions: 13656300 bytes\n","2021-05-05 18:28:34,663 : INFO : resetting layer weights\n","2021-05-05 18:28:36,016 : INFO : collecting all words and their counts\n","2021-05-05 18:28:36,018 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n","2021-05-05 18:28:36,164 : INFO : PROGRESS: at sentence #10000, processed 33138 words, keeping 10665 word types\n","2021-05-05 18:28:36,312 : INFO : PROGRESS: at sentence #20000, processed 66935 words, keeping 17139 word types\n","2021-05-05 18:28:36,488 : INFO : PROGRESS: at sentence #30000, processed 103943 words, keeping 23072 word types\n","2021-05-05 18:28:36,646 : INFO : PROGRESS: at sentence #40000, processed 137471 words, keeping 27257 word types\n","2021-05-05 18:28:36,794 : INFO : PROGRESS: at sentence #50000, processed 169305 words, keeping 31180 word types\n","2021-05-05 18:28:36,939 : INFO : PROGRESS: at sentence #60000, processed 199034 words, keeping 34584 word types\n","2021-05-05 18:28:37,095 : INFO : PROGRESS: at sentence #70000, processed 232290 words, keeping 38239 word types\n","2021-05-05 18:28:37,257 : INFO : PROGRESS: at sentence #80000, processed 267551 words, keeping 41818 word types\n","2021-05-05 18:28:37,427 : INFO : PROGRESS: at sentence #90000, processed 301884 words, keeping 45072 word types\n","2021-05-05 18:28:37,581 : INFO : PROGRESS: at sentence #100000, processed 335694 words, keeping 48066 word types\n","2021-05-05 18:28:37,743 : INFO : PROGRESS: at sentence #110000, processed 370099 words, keeping 51338 word types\n","2021-05-05 18:28:37,896 : INFO : PROGRESS: at sentence #120000, processed 403504 words, keeping 54166 word types\n","2021-05-05 18:28:38,047 : INFO : PROGRESS: at sentence #130000, processed 436305 words, keeping 56287 word types\n","2021-05-05 18:28:38,076 : INFO : collected 56639 word types from a corpus of 442276 raw words and 131853 sentences\n","2021-05-05 18:28:38,078 : INFO : Loading a fresh vocabulary\n","2021-05-05 18:28:38,305 : INFO : effective_min_count=1 retains 56639 unique words (100% of original 56639, drops 0)\n","2021-05-05 18:28:38,306 : INFO : effective_min_count=1 leaves 442276 word corpus (100% of original 442276, drops 0)\n","2021-05-05 18:28:38,508 : INFO : deleting the raw counts dictionary of 56639 items\n","2021-05-05 18:28:38,510 : INFO : sample=0.001 downsamples 18 most-common words\n","2021-05-05 18:28:38,513 : INFO : downsampling leaves estimated 430451 word corpus (97.3% of prior 442276)\n","2021-05-05 18:28:39,554 : INFO : estimated required memory for 56639 words, 317461 buckets and 200 dimensions: 386331956 bytes\n","2021-05-05 18:28:39,571 : INFO : resetting layer weights\n","2021-05-05 18:28:53,357 : INFO : Total number of ngrams is 317461\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q7TOTRFPT96o","executionInfo":{"status":"ok","timestamp":1620239426125,"user_tz":420,"elapsed":48675,"user":{"displayName":"MAURICIO JESÚS ARANEDA","photoUrl":"","userId":"01648930000647588579"}},"outputId":"5ea23cfd-73b9-4bba-acb5-643f3d75f42d"},"source":["t = time()\n","w2v_model.train(sentences, total_examples=w2v_model.corpus_count, epochs=15, report_delay=10)\n","print('Time to train the model: {} mins'.format(round((time() - t) / 60, 2)))\n","if not os.path.exists('./pretrained_models'):\n","    os.mkdir('./pretrained_models')\n","w2v_model.save('./pretrained_models/w2v.model')"],"execution_count":11,"outputs":[{"output_type":"stream","text":["2021-05-05 18:28:57,787 : INFO : training model with 2 workers on 6503 vocabulary and 200 features, using sg=0 hs=0 sample=6e-05 negative=20 window=4\n","2021-05-05 18:28:58,839 : INFO : EPOCH 1 - PROGRESS: at 30.95% examples, 61695 words/s, in_qsize 0, out_qsize 0\n","2021-05-05 18:29:00,999 : INFO : worker thread finished; awaiting finish of 1 more threads\n","2021-05-05 18:29:01,017 : INFO : worker thread finished; awaiting finish of 0 more threads\n","2021-05-05 18:29:01,019 : INFO : EPOCH - 1 : training on 442276 raw words (203285 effective words) took 3.2s, 63158 effective words/s\n","2021-05-05 18:29:02,098 : INFO : EPOCH 2 - PROGRESS: at 28.59% examples, 55378 words/s, in_qsize 1, out_qsize 0\n","2021-05-05 18:29:04,209 : INFO : worker thread finished; awaiting finish of 1 more threads\n","2021-05-05 18:29:04,226 : INFO : worker thread finished; awaiting finish of 0 more threads\n","2021-05-05 18:29:04,227 : INFO : EPOCH - 2 : training on 442276 raw words (203086 effective words) took 3.2s, 63467 effective words/s\n","2021-05-05 18:29:05,263 : INFO : EPOCH 3 - PROGRESS: at 28.59% examples, 57682 words/s, in_qsize 1, out_qsize 0\n","2021-05-05 18:29:07,362 : INFO : worker thread finished; awaiting finish of 1 more threads\n","2021-05-05 18:29:07,385 : INFO : worker thread finished; awaiting finish of 0 more threads\n","2021-05-05 18:29:07,389 : INFO : EPOCH - 3 : training on 442276 raw words (203144 effective words) took 3.2s, 64473 effective words/s\n","2021-05-05 18:29:08,456 : INFO : EPOCH 4 - PROGRESS: at 28.59% examples, 56205 words/s, in_qsize 0, out_qsize 0\n","2021-05-05 18:29:10,699 : INFO : worker thread finished; awaiting finish of 1 more threads\n","2021-05-05 18:29:10,713 : INFO : worker thread finished; awaiting finish of 0 more threads\n","2021-05-05 18:29:10,717 : INFO : EPOCH - 4 : training on 442276 raw words (203108 effective words) took 3.3s, 61194 effective words/s\n","2021-05-05 18:29:11,800 : INFO : EPOCH 5 - PROGRESS: at 33.30% examples, 64087 words/s, in_qsize 1, out_qsize 0\n","2021-05-05 18:29:13,917 : INFO : worker thread finished; awaiting finish of 1 more threads\n","2021-05-05 18:29:13,937 : INFO : worker thread finished; awaiting finish of 0 more threads\n","2021-05-05 18:29:13,939 : INFO : EPOCH - 5 : training on 442276 raw words (203273 effective words) took 3.2s, 63314 effective words/s\n","2021-05-05 18:29:14,964 : INFO : EPOCH 6 - PROGRESS: at 30.95% examples, 63289 words/s, in_qsize 0, out_qsize 0\n","2021-05-05 18:29:17,109 : INFO : worker thread finished; awaiting finish of 1 more threads\n","2021-05-05 18:29:17,131 : INFO : worker thread finished; awaiting finish of 0 more threads\n","2021-05-05 18:29:17,132 : INFO : EPOCH - 6 : training on 442276 raw words (203504 effective words) took 3.2s, 63901 effective words/s\n","2021-05-05 18:29:18,153 : INFO : EPOCH 7 - PROGRESS: at 30.95% examples, 63420 words/s, in_qsize 0, out_qsize 0\n","2021-05-05 18:29:20,330 : INFO : worker thread finished; awaiting finish of 1 more threads\n","2021-05-05 18:29:20,355 : INFO : worker thread finished; awaiting finish of 0 more threads\n","2021-05-05 18:29:20,357 : INFO : EPOCH - 7 : training on 442276 raw words (203278 effective words) took 3.2s, 63232 effective words/s\n","2021-05-05 18:29:21,372 : INFO : EPOCH 8 - PROGRESS: at 30.95% examples, 63774 words/s, in_qsize 0, out_qsize 0\n","2021-05-05 18:29:23,537 : INFO : worker thread finished; awaiting finish of 1 more threads\n","2021-05-05 18:29:23,553 : INFO : worker thread finished; awaiting finish of 0 more threads\n","2021-05-05 18:29:23,554 : INFO : EPOCH - 8 : training on 442276 raw words (203149 effective words) took 3.2s, 63723 effective words/s\n","2021-05-05 18:29:24,571 : INFO : EPOCH 9 - PROGRESS: at 30.95% examples, 63682 words/s, in_qsize 1, out_qsize 0\n","2021-05-05 18:29:26,711 : INFO : worker thread finished; awaiting finish of 1 more threads\n","2021-05-05 18:29:26,736 : INFO : worker thread finished; awaiting finish of 0 more threads\n","2021-05-05 18:29:26,737 : INFO : EPOCH - 9 : training on 442276 raw words (203085 effective words) took 3.2s, 64011 effective words/s\n","2021-05-05 18:29:27,826 : INFO : EPOCH 10 - PROGRESS: at 33.30% examples, 64009 words/s, in_qsize 1, out_qsize 0\n","2021-05-05 18:29:29,900 : INFO : worker thread finished; awaiting finish of 1 more threads\n","2021-05-05 18:29:29,919 : INFO : worker thread finished; awaiting finish of 0 more threads\n","2021-05-05 18:29:29,920 : INFO : EPOCH - 10 : training on 442276 raw words (203333 effective words) took 3.2s, 64169 effective words/s\n","2021-05-05 18:29:30,943 : INFO : EPOCH 11 - PROGRESS: at 30.95% examples, 63292 words/s, in_qsize 0, out_qsize 0\n","2021-05-05 18:29:33,112 : INFO : worker thread finished; awaiting finish of 1 more threads\n","2021-05-05 18:29:33,128 : INFO : worker thread finished; awaiting finish of 0 more threads\n","2021-05-05 18:29:33,132 : INFO : EPOCH - 11 : training on 442276 raw words (203259 effective words) took 3.2s, 63448 effective words/s\n","2021-05-05 18:29:34,238 : INFO : EPOCH 12 - PROGRESS: at 30.95% examples, 58422 words/s, in_qsize 0, out_qsize 0\n","2021-05-05 18:29:36,302 : INFO : worker thread finished; awaiting finish of 1 more threads\n","2021-05-05 18:29:36,323 : INFO : worker thread finished; awaiting finish of 0 more threads\n","2021-05-05 18:29:36,325 : INFO : EPOCH - 12 : training on 442276 raw words (203134 effective words) took 3.2s, 63817 effective words/s\n","2021-05-05 18:29:37,374 : INFO : EPOCH 13 - PROGRESS: at 28.59% examples, 57365 words/s, in_qsize 0, out_qsize 0\n","2021-05-05 18:29:39,487 : INFO : worker thread finished; awaiting finish of 1 more threads\n","2021-05-05 18:29:39,510 : INFO : worker thread finished; awaiting finish of 0 more threads\n","2021-05-05 18:29:39,512 : INFO : EPOCH - 13 : training on 442276 raw words (203282 effective words) took 3.2s, 64085 effective words/s\n","2021-05-05 18:29:40,564 : INFO : EPOCH 14 - PROGRESS: at 28.59% examples, 57035 words/s, in_qsize 0, out_qsize 0\n","2021-05-05 18:29:42,792 : INFO : worker thread finished; awaiting finish of 1 more threads\n","2021-05-05 18:29:42,810 : INFO : worker thread finished; awaiting finish of 0 more threads\n","2021-05-05 18:29:42,811 : INFO : EPOCH - 14 : training on 442276 raw words (203393 effective words) took 3.3s, 61853 effective words/s\n","2021-05-05 18:29:43,852 : INFO : EPOCH 15 - PROGRESS: at 30.95% examples, 62202 words/s, in_qsize 0, out_qsize 0\n","2021-05-05 18:29:45,988 : INFO : worker thread finished; awaiting finish of 1 more threads\n","2021-05-05 18:29:46,006 : INFO : worker thread finished; awaiting finish of 0 more threads\n","2021-05-05 18:29:46,008 : INFO : EPOCH - 15 : training on 442276 raw words (202958 effective words) took 3.2s, 63727 effective words/s\n","2021-05-05 18:29:46,012 : INFO : training on a 6634140 raw words (3048271 effective words) took 48.2s, 63213 effective words/s\n","2021-05-05 18:29:46,017 : INFO : saving Word2Vec object under ./pretrained_models/w2v.model, separately None\n","2021-05-05 18:29:46,019 : INFO : not storing attribute vectors_norm\n","2021-05-05 18:29:46,023 : INFO : not storing attribute cum_table\n","2021-05-05 18:29:46,151 : INFO : saved ./pretrained_models/w2v.model\n"],"name":"stderr"},{"output_type":"stream","text":["Time to train the model: 0.8 mins\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BVBDylJDT96o","executionInfo":{"status":"ok","timestamp":1620239519765,"user_tz":420,"elapsed":80396,"user":{"displayName":"MAURICIO JESÚS ARANEDA","photoUrl":"","userId":"01648930000647588579"}},"outputId":"f6afb226-2aa7-4804-a796-30c74bf35603"},"source":["t = time()\n","ft_model.train(sentences, total_examples=ft_model.corpus_count, epochs=15, report_delay=10)\n","print('Time to train the model: {} mins'.format(round((time() - t) / 60, 2)))\n","if not os.path.exists('./pretrained_models'):\n","    os.mkdir('./pretrained_models')\n","ft_model.save('./pretrained_models/ft.model')"],"execution_count":12,"outputs":[{"output_type":"stream","text":["2021-05-05 18:29:59,687 : INFO : training model with 3 workers on 56639 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=5 window=3\n","2021-05-05 18:30:00,778 : INFO : EPOCH 1 - PROGRESS: at 19.90% examples, 81212 words/s, in_qsize 0, out_qsize 0\n","2021-05-05 18:30:04,621 : INFO : worker thread finished; awaiting finish of 2 more threads\n","2021-05-05 18:30:04,655 : INFO : worker thread finished; awaiting finish of 1 more threads\n","2021-05-05 18:30:04,705 : INFO : worker thread finished; awaiting finish of 0 more threads\n","2021-05-05 18:30:04,706 : INFO : EPOCH - 1 : training on 442276 raw words (430539 effective words) took 5.0s, 86066 effective words/s\n","2021-05-05 18:30:05,794 : INFO : EPOCH 2 - PROGRESS: at 19.90% examples, 81508 words/s, in_qsize 0, out_qsize 0\n","2021-05-05 18:30:09,547 : INFO : worker thread finished; awaiting finish of 2 more threads\n","2021-05-05 18:30:09,584 : INFO : worker thread finished; awaiting finish of 1 more threads\n","2021-05-05 18:30:09,624 : INFO : worker thread finished; awaiting finish of 0 more threads\n","2021-05-05 18:30:09,626 : INFO : EPOCH - 2 : training on 442276 raw words (430467 effective words) took 4.9s, 87819 effective words/s\n","2021-05-05 18:30:10,655 : INFO : EPOCH 3 - PROGRESS: at 17.92% examples, 76051 words/s, in_qsize 0, out_qsize 0\n","2021-05-05 18:30:14,636 : INFO : worker thread finished; awaiting finish of 2 more threads\n","2021-05-05 18:30:14,673 : INFO : worker thread finished; awaiting finish of 1 more threads\n","2021-05-05 18:30:14,717 : INFO : worker thread finished; awaiting finish of 0 more threads\n","2021-05-05 18:30:14,719 : INFO : EPOCH - 3 : training on 442276 raw words (430364 effective words) took 5.1s, 84675 effective words/s\n","2021-05-05 18:30:15,762 : INFO : EPOCH 4 - PROGRESS: at 19.90% examples, 84627 words/s, in_qsize 0, out_qsize 0\n","2021-05-05 18:30:19,593 : INFO : worker thread finished; awaiting finish of 2 more threads\n","2021-05-05 18:30:19,619 : INFO : worker thread finished; awaiting finish of 1 more threads\n","2021-05-05 18:30:19,674 : INFO : worker thread finished; awaiting finish of 0 more threads\n","2021-05-05 18:30:19,677 : INFO : EPOCH - 4 : training on 442276 raw words (430460 effective words) took 4.9s, 87028 effective words/s\n","2021-05-05 18:30:20,720 : INFO : EPOCH 5 - PROGRESS: at 19.90% examples, 84731 words/s, in_qsize 0, out_qsize 0\n","2021-05-05 18:30:24,521 : INFO : worker thread finished; awaiting finish of 2 more threads\n","2021-05-05 18:30:24,555 : INFO : worker thread finished; awaiting finish of 1 more threads\n","2021-05-05 18:30:24,613 : INFO : worker thread finished; awaiting finish of 0 more threads\n","2021-05-05 18:30:24,614 : INFO : EPOCH - 5 : training on 442276 raw words (430418 effective words) took 4.9s, 87424 effective words/s\n","2021-05-05 18:30:25,674 : INFO : EPOCH 6 - PROGRESS: at 19.90% examples, 83495 words/s, in_qsize 0, out_qsize 0\n","2021-05-05 18:30:29,484 : INFO : worker thread finished; awaiting finish of 2 more threads\n","2021-05-05 18:30:29,488 : INFO : worker thread finished; awaiting finish of 1 more threads\n","2021-05-05 18:30:29,517 : INFO : worker thread finished; awaiting finish of 0 more threads\n","2021-05-05 18:30:29,518 : INFO : EPOCH - 6 : training on 442276 raw words (430480 effective words) took 4.9s, 88057 effective words/s\n","2021-05-05 18:30:30,545 : INFO : EPOCH 7 - PROGRESS: at 17.92% examples, 76427 words/s, in_qsize 0, out_qsize 0\n","2021-05-05 18:30:34,469 : INFO : worker thread finished; awaiting finish of 2 more threads\n","2021-05-05 18:30:34,503 : INFO : worker thread finished; awaiting finish of 1 more threads\n","2021-05-05 18:30:34,545 : INFO : worker thread finished; awaiting finish of 0 more threads\n","2021-05-05 18:30:34,546 : INFO : EPOCH - 7 : training on 442276 raw words (430507 effective words) took 5.0s, 85835 effective words/s\n","2021-05-05 18:30:35,578 : INFO : EPOCH 8 - PROGRESS: at 19.90% examples, 85812 words/s, in_qsize 0, out_qsize 0\n","2021-05-05 18:30:39,420 : INFO : worker thread finished; awaiting finish of 2 more threads\n","2021-05-05 18:30:39,428 : INFO : worker thread finished; awaiting finish of 1 more threads\n","2021-05-05 18:30:39,486 : INFO : worker thread finished; awaiting finish of 0 more threads\n","2021-05-05 18:30:39,487 : INFO : EPOCH - 8 : training on 442276 raw words (430395 effective words) took 4.9s, 87379 effective words/s\n","2021-05-05 18:30:40,542 : INFO : EPOCH 9 - PROGRESS: at 19.90% examples, 83629 words/s, in_qsize 0, out_qsize 0\n","2021-05-05 18:30:44,284 : INFO : worker thread finished; awaiting finish of 2 more threads\n","2021-05-05 18:30:44,317 : INFO : worker thread finished; awaiting finish of 1 more threads\n","2021-05-05 18:30:44,363 : INFO : worker thread finished; awaiting finish of 0 more threads\n","2021-05-05 18:30:44,365 : INFO : EPOCH - 9 : training on 442276 raw words (430425 effective words) took 4.9s, 88471 effective words/s\n","2021-05-05 18:30:45,424 : INFO : EPOCH 10 - PROGRESS: at 19.90% examples, 83354 words/s, in_qsize 0, out_qsize 0\n","2021-05-05 18:30:49,183 : INFO : worker thread finished; awaiting finish of 2 more threads\n","2021-05-05 18:30:49,221 : INFO : worker thread finished; awaiting finish of 1 more threads\n","2021-05-05 18:30:49,275 : INFO : worker thread finished; awaiting finish of 0 more threads\n","2021-05-05 18:30:49,277 : INFO : EPOCH - 10 : training on 442276 raw words (430435 effective words) took 4.9s, 87863 effective words/s\n","2021-05-05 18:30:50,324 : INFO : EPOCH 11 - PROGRESS: at 17.92% examples, 74944 words/s, in_qsize 0, out_qsize 0\n","2021-05-05 18:30:54,204 : INFO : worker thread finished; awaiting finish of 2 more threads\n","2021-05-05 18:30:54,241 : INFO : worker thread finished; awaiting finish of 1 more threads\n","2021-05-05 18:30:54,304 : INFO : worker thread finished; awaiting finish of 0 more threads\n","2021-05-05 18:30:54,307 : INFO : EPOCH - 11 : training on 442276 raw words (430478 effective words) took 5.0s, 85817 effective words/s\n","2021-05-05 18:30:55,378 : INFO : EPOCH 12 - PROGRESS: at 19.90% examples, 82429 words/s, in_qsize 0, out_qsize 0\n","2021-05-05 18:30:59,216 : INFO : worker thread finished; awaiting finish of 2 more threads\n","2021-05-05 18:30:59,238 : INFO : worker thread finished; awaiting finish of 1 more threads\n","2021-05-05 18:30:59,278 : INFO : worker thread finished; awaiting finish of 0 more threads\n","2021-05-05 18:30:59,280 : INFO : EPOCH - 12 : training on 442276 raw words (430389 effective words) took 5.0s, 86775 effective words/s\n","2021-05-05 18:31:00,368 : INFO : EPOCH 13 - PROGRESS: at 19.90% examples, 80998 words/s, in_qsize 0, out_qsize 0\n","2021-05-05 18:31:04,163 : INFO : worker thread finished; awaiting finish of 2 more threads\n","2021-05-05 18:31:04,174 : INFO : worker thread finished; awaiting finish of 1 more threads\n","2021-05-05 18:31:04,198 : INFO : worker thread finished; awaiting finish of 0 more threads\n","2021-05-05 18:31:04,200 : INFO : EPOCH - 13 : training on 442276 raw words (430368 effective words) took 4.9s, 87685 effective words/s\n","2021-05-05 18:31:05,267 : INFO : EPOCH 14 - PROGRESS: at 19.90% examples, 82979 words/s, in_qsize 0, out_qsize 0\n","2021-05-05 18:31:09,065 : INFO : worker thread finished; awaiting finish of 2 more threads\n","2021-05-05 18:31:09,070 : INFO : worker thread finished; awaiting finish of 1 more threads\n","2021-05-05 18:31:09,123 : INFO : worker thread finished; awaiting finish of 0 more threads\n","2021-05-05 18:31:09,125 : INFO : EPOCH - 14 : training on 442276 raw words (430700 effective words) took 4.9s, 87727 effective words/s\n","2021-05-05 18:31:10,203 : INFO : EPOCH 15 - PROGRESS: at 17.92% examples, 72704 words/s, in_qsize 0, out_qsize 0\n","2021-05-05 18:31:14,063 : INFO : worker thread finished; awaiting finish of 2 more threads\n","2021-05-05 18:31:14,091 : INFO : worker thread finished; awaiting finish of 1 more threads\n","2021-05-05 18:31:14,146 : INFO : worker thread finished; awaiting finish of 0 more threads\n","2021-05-05 18:31:14,148 : INFO : EPOCH - 15 : training on 442276 raw words (430341 effective words) took 5.0s, 85867 effective words/s\n","2021-05-05 18:31:14,150 : INFO : training on a 6634140 raw words (6456766 effective words) took 74.5s, 86715 effective words/s\n","2021-05-05 18:31:17,648 : INFO : saving FastText object under ./pretrained_models/ft.model, separately None\n","2021-05-05 18:31:17,649 : INFO : storing np array 'vectors' to ./pretrained_models/ft.model.wv.vectors.npy\n","2021-05-05 18:31:17,692 : INFO : storing np array 'vectors_vocab' to ./pretrained_models/ft.model.wv.vectors_vocab.npy\n","2021-05-05 18:31:17,737 : INFO : storing np array 'vectors_ngrams' to ./pretrained_models/ft.model.wv.vectors_ngrams.npy\n"],"name":"stderr"},{"output_type":"stream","text":["Time to train the model: 1.3 mins\n"],"name":"stdout"},{"output_type":"stream","text":["2021-05-05 18:31:18,219 : INFO : not storing attribute vectors_norm\n","2021-05-05 18:31:18,221 : INFO : not storing attribute vectors_vocab_norm\n","2021-05-05 18:31:18,228 : INFO : not storing attribute vectors_ngrams_norm\n","2021-05-05 18:31:18,230 : INFO : not storing attribute buckets_word\n","2021-05-05 18:31:18,232 : INFO : storing np array 'syn1neg' to ./pretrained_models/ft.model.trainables.syn1neg.npy\n","2021-05-05 18:31:18,410 : INFO : storing np array 'vectors_vocab_lockf' to ./pretrained_models/ft.model.trainables.vectors_vocab_lockf.npy\n","2021-05-05 18:31:18,545 : INFO : storing np array 'vectors_ngrams_lockf' to ./pretrained_models/ft.model.trainables.vectors_ngrams_lockf.npy\n","2021-05-05 18:31:19,755 : INFO : saved ./pretrained_models/ft.model\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"nqdIfD_6T96p"},"source":["**Pregunta 2**: Encuentre las palabras mas similares a las siguientes: Lisa, Bart, Homer, Marge. Cúal es la diferencia entre ambos resultados? Por qué ocurre esto? Intente comparar ahora Liisa en ambos modelos (doble i). Cuando escogería uno vs el otro? (2 puntos)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bW9HY306T96p","executionInfo":{"status":"ok","timestamp":1620239655781,"user_tz":420,"elapsed":320,"user":{"displayName":"MAURICIO JESÚS ARANEDA","photoUrl":"","userId":"01648930000647588579"}},"outputId":"96c00f9c-b26a-42f8-d6f4-0e0cb5e881fe"},"source":["w2v_model.wv.most_similar(positive=[\"Lisa\"])"],"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('week', 0.9985420107841492),\n"," ('Simpson', 0.9983469843864441),\n"," ('father', 0.9982574582099915),\n"," ('family', 0.998214066028595),\n"," ('worry', 0.9982051849365234),\n"," ('Listen', 0.9982007741928101),\n"," ('wife', 0.9981789588928223),\n"," ('person', 0.9981776475906372),\n"," ('kids', 0.9981535077095032),\n"," ('Lisas', 0.9980610609054565)]"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gN8w6sCGT96p","executionInfo":{"status":"ok","timestamp":1620239657446,"user_tz":420,"elapsed":672,"user":{"displayName":"MAURICIO JESÚS ARANEDA","photoUrl":"","userId":"01648930000647588579"}},"outputId":"12a508a0-3a7f-43df-ef8e-013df57e58c4"},"source":["ft_model.wv.most_similar(positive=[\"Lisa\"])"],"execution_count":15,"outputs":[{"output_type":"stream","text":["2021-05-05 18:33:37,074 : INFO : precomputing L2-norms of word weight vectors\n","2021-05-05 18:33:37,133 : INFO : precomputing L2-norms of ngram weight vectors\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["[('Lisaaa', 0.9817751049995422),\n"," ('Lisasa', 0.9789548516273499),\n"," ('isa', 0.969172477722168),\n"," ('BartBart', 0.9586920738220215),\n"," ('Bart', 0.958591878414154),\n"," ('Lisui', 0.9568639993667603),\n"," ('BBart', 0.955807626247406),\n"," ('Bartd', 0.9493404626846313),\n"," ('Lisas', 0.9315504431724548),\n"," ('Barto', 0.9291247725486755)]"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pcdFrFNUT96q","executionInfo":{"status":"ok","timestamp":1620239659033,"user_tz":420,"elapsed":266,"user":{"displayName":"MAURICIO JESÚS ARANEDA","photoUrl":"","userId":"01648930000647588579"}},"outputId":"724d2c32-e862-470a-afdf-6a302b6dcf45"},"source":["w2v_model.wv.most_similar(positive=[\"Bart\"])"],"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('Marge', 0.9980909824371338),\n"," ('love', 0.996785581111908),\n"," ('morning', 0.9964793920516968),\n"," ('lot', 0.9962568283081055),\n"," ('kids', 0.996232807636261),\n"," ('house', 0.9961422681808472),\n"," ('family', 0.9958850145339966),\n"," ('Mom', 0.9957067966461182),\n"," ('Dad', 0.9956257343292236),\n"," ('Maggie', 0.9956096410751343)]"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JIFpX3LPT96q","executionInfo":{"status":"ok","timestamp":1620239659704,"user_tz":420,"elapsed":361,"user":{"displayName":"MAURICIO JESÚS ARANEDA","photoUrl":"","userId":"01648930000647588579"}},"outputId":"a6160f97-c31f-41d7-a40f-384dd72799f2"},"source":["ft_model.wv.most_similar(positive=[\"Bart\"])"],"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('BartBart', 0.996340811252594),\n"," ('BBart', 0.9906246662139893),\n"," ('Bartd', 0.9884854555130005),\n"," ('Barto', 0.9657625555992126),\n"," ('himBart', 0.962405800819397),\n"," ('Lisa', 0.958591878414154),\n"," ('Bartolo', 0.9534002542495728),\n"," ('Lisasa', 0.9527678489685059),\n"," ('Lisaaa', 0.9518307447433472),\n"," ('girlBart', 0.945798933506012)]"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SYm8JrrQT96q","executionInfo":{"status":"ok","timestamp":1620239661046,"user_tz":420,"elapsed":262,"user":{"displayName":"MAURICIO JESÚS ARANEDA","photoUrl":"","userId":"01648930000647588579"}},"outputId":"3f393180-b1d3-470e-ab5e-32ecff1185d9"},"source":["w2v_model.wv.most_similar(positive=[\"Homer\"])"],"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('Dad', 0.9976283311843872),\n"," ('kids', 0.9972633719444275),\n"," ('gotta', 0.9967912435531616),\n"," ('lot', 0.9963006973266602),\n"," ('family', 0.9962224960327148),\n"," ('idea', 0.996216893196106),\n"," ('wondering', 0.9961588382720947),\n"," ('love', 0.996137261390686),\n"," ('uh', 0.9960238933563232),\n"," ('money', 0.9960137605667114)]"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WL9-5iXhT96q","executionInfo":{"status":"ok","timestamp":1620239662364,"user_tz":420,"elapsed":424,"user":{"displayName":"MAURICIO JESÚS ARANEDA","photoUrl":"","userId":"01648930000647588579"}},"outputId":"76611ad2-c3f5-4c8f-bdfc-92f524df5983"},"source":["ft_model.wv.most_similar(positive=['Homer'])"],"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('HomerCo', 0.9786771535873413),\n"," ('Homerun', 0.9725373983383179),\n"," ('Homerdo', 0.9692320227622986),\n"," ('HomeEc', 0.9651811122894287),\n"," ('HomeIE', 0.9628790616989136),\n"," ('Homerhol', 0.961715817451477),\n"," ('Homerll', 0.9604755640029907),\n"," ('Homeo', 0.9591439962387085),\n"," ('HomerJay', 0.9518280029296875),\n"," ('Homeroni', 0.9358807802200317)]"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DTRBwExQT96r","executionInfo":{"status":"ok","timestamp":1620239663461,"user_tz":420,"elapsed":320,"user":{"displayName":"MAURICIO JESÚS ARANEDA","photoUrl":"","userId":"01648930000647588579"}},"outputId":"ddae64da-27af-4b4d-cfad-57423b16ef29"},"source":["w2v_model.wv.most_similar(positive=[\"Marge\"])"],"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('Bart', 0.9980909824371338),\n"," ('love', 0.9977885484695435),\n"," ('lot', 0.9976247549057007),\n"," ('house', 0.9976038932800293),\n"," ('kids', 0.9972618818283081),\n"," ('morning', 0.9970948696136475),\n"," ('worry', 0.9969012141227722),\n"," ('family', 0.9968920946121216),\n"," ('money', 0.9968373775482178),\n"," ('Mom', 0.9968361854553223)]"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GXAIzB32T96r","executionInfo":{"status":"ok","timestamp":1620239665211,"user_tz":420,"elapsed":339,"user":{"displayName":"MAURICIO JESÚS ARANEDA","photoUrl":"","userId":"01648930000647588579"}},"outputId":"c15685df-0c64-4f85-debd-92717e309826"},"source":["ft_model.wv.most_similar(positive=[\"Marge\"])"],"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('withMarge', 0.9610694646835327),\n"," ('Margebot', 0.9524004459381104),\n"," ('Rarge', 0.9319246411323547),\n"," ('Maarge', 0.9314150810241699),\n"," ('Margelovin', 0.921453595161438),\n"," ('Marges', 0.9165328741073608),\n"," ('Maaarge', 0.9141896963119507),\n"," ('Margell', 0.9062343835830688),\n"," ('Sarge', 0.905869722366333),\n"," ('Margie', 0.899062991142273)]"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":325},"id":"-TJfQTAaT96r","executionInfo":{"status":"error","timestamp":1620239666173,"user_tz":420,"elapsed":358,"user":{"displayName":"MAURICIO JESÚS ARANEDA","photoUrl":"","userId":"01648930000647588579"}},"outputId":"549fb4af-393e-44c4-8818-de0f4db60a5b"},"source":["w2v_model.wv.most_similar(positive=[\"Liisa\"]) # Es normal el siguiente error!"],"execution_count":22,"outputs":[{"output_type":"error","ename":"KeyError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-22-a2af44600479>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mw2v_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpositive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Liisa\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Es normal el siguiente error!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mmost_similar\u001b[0;34m(self, positive, negative, topn, restrict_vocab, indexer)\u001b[0m\n\u001b[1;32m    529\u001b[0m                 \u001b[0mmean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m                 \u001b[0mmean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m                     \u001b[0mall_words\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mword_vec\u001b[0;34m(self, word, use_norm)\u001b[0m\n\u001b[1;32m    450\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"word '%s' not in vocabulary\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: \"word 'Liisa' not in vocabulary\""]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iscce2TmT96s","executionInfo":{"status":"ok","timestamp":1620239669942,"user_tz":420,"elapsed":354,"user":{"displayName":"MAURICIO JESÚS ARANEDA","photoUrl":"","userId":"01648930000647588579"}},"outputId":"575f5267-2ad6-43bc-c098-033a8dd3baa4"},"source":["ft_model.wv.most_similar(positive=[\"Liisa\"])"],"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('Liiiisaaa', 0.9868066310882568),\n"," ('Liiisaaa', 0.9857814311981201),\n"," ('Liza', 0.9811402559280396),\n"," ('Lil', 0.9783587455749512),\n"," ('Lisabella', 0.9764255285263062),\n"," ('Limo', 0.9758217930793762),\n"," ('Limb', 0.9738129377365112),\n"," ('Lhasa', 0.9731556177139282),\n"," ('Lincoln', 0.9722809195518494),\n"," ('TVsa', 0.9718849658966064)]"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"markdown","metadata":{"id":"imTI7-NuT96s"},"source":["W2V encuentra las palabras del vocabulario que están mas cerca mientras que FastText busca los ngramas. FastText funciona mejor que W2V cuando buscamos palabras que están fuera del vocabulario."]},{"cell_type":"markdown","metadata":{"id":"KKfVTHQhT96s"},"source":["### Parte 4: Aplicar embeddings para clasificar"]},{"cell_type":"markdown","metadata":{"id":"lHxLGviGT96s"},"source":["Ahora utilizaremos los embeddings que acabamos de calcular para clasificar palabras basadas en su polaridad (positivas o negativas). \n","\n","Para esto ocuparemos el lexicón AFINN incluido en la tarea, que incluye una lista de palabras y un 1 si su connotación es positiva y un -1 si es negativa."]},{"cell_type":"code","metadata":{"id":"dmQYAFasT96s","executionInfo":{"status":"ok","timestamp":1620239727334,"user_tz":420,"elapsed":354,"user":{"displayName":"MAURICIO JESÚS ARANEDA","photoUrl":"","userId":"01648930000647588579"}}},"source":["AFINN = 'AFINN_full.csv'\n","df_afinn = pd.read_csv(AFINN, sep='\\t', header=None)"],"execution_count":27,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KrvvydndT96s"},"source":["Hint: Para w2v son esperables KeyErrors debido a que no todas las palabras del corpus de los simpsons tendrán una representación en AFINN. Pueden utilizar esta función auxiliar para filtrar las filas en el dataframe que no tienen embeddings (como w2v no tiene token UNK se deben ignorar)."]},{"cell_type":"code","metadata":{"id":"C9w-3N_0T96t","executionInfo":{"status":"ok","timestamp":1620239698049,"user_tz":420,"elapsed":319,"user":{"displayName":"MAURICIO JESÚS ARANEDA","photoUrl":"","userId":"01648930000647588579"}}},"source":["def try_apply(model,word):\n","    try:\n","        aux = model[word]\n","        return True\n","    except KeyError:\n","        #logger.error('Word {} not in dictionary'.format(word))\n","        return False"],"execution_count":25,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WbBQPCW-T96t"},"source":["**Pregunta 1**: Transforme las palabras del corpus de AFINN a la representación en embedding que acabamos de calcular. Su dataframe final debe ser del estilo [embedding, sentimiento]. Donde $X$ corresponde a los embeddings y $y$ corresponde al sentimiento asociado al embedding (positivo/negativo, 1/-1). para ambos modelos, separarlo utilizando la siguiente función, donde X es su columna de embeddings e y es la columna de los valores. (3 puntos)"]},{"cell_type":"code","metadata":{"id":"Q4hnmoLBT96t"},"source":["X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, test_size=0.1, stratify=y)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PB1dsrdYT96u"},"source":["**Respuesta**:"]},{"cell_type":"code","metadata":{"id":"bmh6Ox7iT96u","executionInfo":{"status":"ok","timestamp":1620239910033,"user_tz":420,"elapsed":117795,"user":{"displayName":"MAURICIO JESÚS ARANEDA","photoUrl":"","userId":"01648930000647588579"}}},"source":["df_afinn = df_afinn[df_afinn[0].apply(lambda x: try_apply(ft_model.wv,x))]\n","df_afinn[0] = df_afinn[0].apply(lambda x: ft_model.wv[x])\n","X = np.stack(df_afinn[0].values)\n","y = df_afinn[1].values\n","X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, test_size=0.1, stratify=y)"],"execution_count":33,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iW86FVJQ1XSh","executionInfo":{"status":"ok","timestamp":1620241671161,"user_tz":420,"elapsed":362,"user":{"displayName":"MAURICIO JESÚS ARANEDA","photoUrl":"","userId":"01648930000647588579"}},"outputId":"9e955a05-a60e-4ea6-c1d7-c0343d1fea9e"},"source":["y"],"execution_count":35,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([ 1, -1,  1, ..., -1, -1, -1])"]},"metadata":{"tags":[]},"execution_count":35}]},{"cell_type":"markdown","metadata":{"id":"jdI5lPbDT96u"},"source":["**Pregunta 2**: Entrenar una regresión logística (vista en auxiliar) y reportar accuracy, precision, recall, f1 y confusion_matrix para ambos modelos. Por qué se obtienen estos resultados? Cómo los mejorarías? (3 puntos)"]},{"cell_type":"code","metadata":{"id":"1XgJ861GT96u"},"source":["reg = linear_model.LogisticRegression(penalty='l2', solver='liblinear', C=1)\n","reg.fit(X_train, y_train)\n","y_pred = reg.predict(X_test)\n","acc = accuracy_score(y_test, y_pred)\n","pre = precision_score(y_test, y_pred)\n","rec = recall_score(y_test, y_pred)\n","f1 = f1_score(y_test, y_pred)\n","conf = confusion_matrix(y_test, y_pred)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZzoDNWVRT96u","outputId":"be75f6aa-6a00-4370-e8f6-1c222d3ce2fd"},"source":["logger.info(\"The accuracy is {0}\".format(acc))\n","logger.info(\"The precision is {0}\".format(pre))\n","logger.info(\"The recall is {0}\".format(rec))\n","logger.info(\"The f1 score is {0}\".format(f1))\n","logger.info(\"The confusion matrix:\\n{0}\".format(conf))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2020-05-07 21:55:03,449 : INFO : The accuracy is 0.696165191740413\n","2020-05-07 21:55:03,450 : INFO : The precision is 0.7419354838709677\n","2020-05-07 21:55:03,450 : INFO : The recall is 0.19491525423728814\n","2020-05-07 21:55:03,451 : INFO : The f1 score is 0.30872483221476515\n","2020-05-07 21:55:03,451 : INFO : The confusion matrix:\n","[[213   8]\n"," [ 95  23]]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"scrolled":true,"id":"t0r8d9MMT96v","outputId":"5bbac6b3-7c52-46e8-95df-43c558e11a96"},"source":["df_afinn = pd.read_csv(AFINN, sep='\\t', header=None)\n","df_afinn = df_afinn[df_afinn[0].apply(lambda x: try_apply(w2v_model,x))]\n","df_afinn[0] = df_afinn[0].apply(lambda x: w2v_model[x])\n","X = np.stack(df_afinn[0].values)\n","y = df_afinn[1].values\n","X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, test_size=0.1, stratify=y)\n","reg = linear_model.LogisticRegression(penalty='l2', solver='liblinear', C=1)\n","reg.fit(X_train, y_train)\n","y_pred = reg.predict(X_test)\n","acc = accuracy_score(y_test, y_pred)\n","pre = precision_score(y_test, y_pred)\n","rec = recall_score(y_test, y_pred)\n","f1 = f1_score(y_test, y_pred)\n","conf = confusion_matrix(y_test, y_pred)\n","logger.info(\"The accuracy is {0}\".format(acc))\n","logger.info(\"The precision is {0}\".format(pre))\n","logger.info(\"The recall is {0}\".format(rec))\n","logger.info(\"The f1 score is {0}\".format(f1))\n","logger.info(\"The confusion matrix:\\n{0}\".format(conf))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/home/ctamblay/Desktop/NLP/minitarea3/venv/lib/python3.6/site-packages/ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n","  This is separate from the ipykernel package so we can avoid doing imports until\n","/home/ctamblay/Desktop/NLP/minitarea3/venv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","2020-05-07 21:55:05,093 : INFO : The accuracy is 0.5813953488372093\n","2020-05-07 21:55:05,094 : INFO : The precision is 0.0\n","2020-05-07 21:55:05,095 : INFO : The recall is 0.0\n","2020-05-07 21:55:05,095 : INFO : The f1 score is 0.0\n","2020-05-07 21:55:05,096 : INFO : The confusion matrix:\n","[[50  0]\n"," [36  0]]\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"BTY3btc3T96v"},"source":["Estos resultados son pésimos. Hay 2 razones posibles: El dataset es muy pequeño cómo para que estos modelos logren aprender bien las relaciones entre las palabras o puede que con los diálogos de los Simpson no se obtengan buenos embeddings para clasificar palabras por sentimiento. Se podría mejorar añadiendo mas datos, por ejemplo los subtítulos de las películas o simplemente buscar otro dataset más grande."]},{"cell_type":"markdown","metadata":{"id":"_gE1i-kdT96v"},"source":["# Bonus: 2 puntos en cualquier pregunta"]},{"cell_type":"markdown","metadata":{"id":"iQ96cYOST96v"},"source":["Replicar lo anterior utilizando embeddings pre-entrenados en un dataset más grande y obtener mejores resultados. Les puede servir [esta](https://radimrehurek.com/gensim/downloader.html#module-gensim.downloader) documentacion de gensim (1 punto)."]},{"cell_type":"code","metadata":{"id":"va-ki09KT96v","outputId":"e629229c-23c8-4e49-e05e-a63420a61255"},"source":["df_afinn = pd.read_csv(AFINN, sep='\\t', header=None)\n","import gensim.downloader as api\n","model = api.load(\"glove-wiki-gigaword-300\") \n","df_afinn = df_afinn[df_afinn[0].apply(lambda x: try_apply(model,x))]\n","df_afinn[0] = df_afinn[0].apply(lambda x: model[x])\n","X = np.stack(df_afinn[0].values)\n","y = df_afinn[1].values\n","X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0, test_size=0.1, stratify=y)\n","reg = linear_model.LogisticRegression(penalty='l2', solver='liblinear', C=1)\n","reg.fit(X_train, y_train)\n","y_pred = reg.predict(X_test)\n","acc = accuracy_score(y_test, y_pred)\n","pre = precision_score(y_test, y_pred)\n","rec = recall_score(y_test, y_pred)\n","f1 = f1_score(y_test, y_pred)\n","conf = confusion_matrix(y_test, y_pred)\n","logger.info(\"The accuracy is {0}\".format(acc))\n","logger.info(\"The precision is {0}\".format(pre))\n","logger.info(\"The recall is {0}\".format(rec))\n","logger.info(\"The f1 score is {0}\".format(f1))\n","logger.info(\"The ROC AUC score is {0}\".format(roc))\n","logger.info(\"The confusion matrix:\\n{0}\".format(conf))\n","logger.info(\"The kappa is {0}\".format(kappa))\n","logger.info(\"Summary report:\\n{0}\".format(class_rep))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2020-05-07 21:55:29,012 : INFO : loading projection weights from /home/ctamblay/gensim-data/glove-wiki-gigaword-300/glove-wiki-gigaword-300.gz\n","2020-05-07 21:56:43,708 : INFO : loaded (400000, 300) matrix from /home/ctamblay/gensim-data/glove-wiki-gigaword-300/glove-wiki-gigaword-300.gz\n","2020-05-07 21:56:43,909 : INFO : The accuracy is 0.913312693498452\n","2020-05-07 21:56:43,910 : INFO : The precision is 0.8818181818181818\n","2020-05-07 21:56:43,910 : INFO : The recall is 0.8660714285714286\n","2020-05-07 21:56:43,911 : INFO : The f1 score is 0.8738738738738738\n","2020-05-07 21:56:43,911 : INFO : The ROC AUC score is 0.9730450236966826\n","2020-05-07 21:56:43,912 : INFO : The confusion matrix:\n","[[198  13]\n"," [ 15  97]]\n","2020-05-07 21:56:43,913 : INFO : The kappa is 0.8078443037436791\n","2020-05-07 21:56:43,913 : INFO : Summary report:\n","              precision    recall  f1-score   support\n","\n","          -1       0.93      0.94      0.93       211\n","           1       0.88      0.87      0.87       112\n","\n","    accuracy                           0.91       323\n","   macro avg       0.91      0.90      0.90       323\n","weighted avg       0.91      0.91      0.91       323\n","\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"u6gfbV2dT96v"},"source":["Utilizar wefe para ver si el modelo w2v entrenado con los dialogos de los Simpson tienen algun bias entre los personajes hombres y la cerveza (1 punto):"]},{"cell_type":"markdown","metadata":{"id":"iVSpJ0E5T96v"},"source":["**Respuesta**:"]},{"cell_type":"code","metadata":{"id":"drNO2cUPT96v"},"source":["from wefe.query import Query\n","from wefe.word_embedding_model import WordEmbeddingModel\n","from wefe.metrics import RND, WEAT"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rxcVXhYKT96v"},"source":["male_words = ['Homer', 'Moe', 'Barney', 'Carl', 'Lenny']\n","female_words = ['Marge']\n","\n","beer = [\n","    'beer', 'Duff', 'alcohol'\n","]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wav3xCOCT96x"},"source":["model = WordEmbeddingModel(w2v_model.wv)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"f5BOCRVIT96x","outputId":"623c29c9-c31b-45e7-d7d6-9e699b95b7e7"},"source":["RND().run_query(\n","    Query([male_words, female_words], [beer], ['Homer Friends', 'Marge Friends'],\n","          ['Beer']), model)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'query_name': 'Homer Friends and Marge Friends wrt Beer',\n"," 'result': -0.12001437942186992,\n"," 'results_by_word': {'beer': -0.13931963,\n","  'Duff': -0.137123,\n","  'alcohol': -0.083600506}}"]},"metadata":{"tags":[]},"execution_count":419}]}]}