{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1KzvykC6jqYIdE9LXFQMIyhBZXcl4KmH6","timestamp":1622526705773}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"UwaDuQqCOyLJ"},"source":["# **Tarea 4 - CC6205 Natural Language Processing üìö**\n","\n","**Integrantes:**\n","\n","**Fecha l√≠mite de entrega üìÜ:** Lunes 06 de junio.\n","\n","**Tiempo estimado de dedicaci√≥n:**"]},{"cell_type":"markdown","metadata":{"id":"X4lL5hGw07yP"},"source":["Bienvenid@s a la cuarta tarea del curso de Natural Language Processing (NLP).\n","En esta tarea estaremos tratando el problema de **tagging** (generaci√≥n de secuencias de etiquetas del mismo largo que la secuencia de input), el uso de **Convolutional Neural Networks** y **Recurrent Neural Networks**, e implementaremos una red usando PyTorch.\n","\n","Usen $\\LaTeX$ para las f√≥rmulas matem√°ticas. En la parte de programaci√≥n pueden usar lo que quieran, pero la [Auxiliar 3](https://youtu.be/36WTXvg3zh0) les puede ser de *gran ayuda*.\n","\n","**Instrucciones:**\n","- La tarea se realiza en grupos de **m√°ximo** 2 personas. Puede ser invidivual pero no es recomendable.\n","- La entrega es a trav√©s de u-cursos a m√°s tardar el d√≠a estipulado arriba. No se aceptan atrasos.\n","- El formato de entrega es este mismo Jupyter Notebook.\n","- Al momento de la revisi√≥n tu c√≥digo ser√° ejecutado. Por favor verifica que tu entrega no tenga errores de compilaci√≥n.\n","- En el horario de auxiliar pueden realizar consultas acerca de la tarea a trav√©s del canal de Discord del curso.\n","\n","Si a√∫n no han visto las clases, se recomienda visitar los links de las referencias.\n","\n","**Referencias:**\n","\n","- [Tagging, and Hidden Markov Models ](http://www.cs.columbia.edu/~mcollins/cs4705-spring2019/slides/tagging.pdf) (slides by Michael Collins), [notes](http://www.cs.columbia.edu/~mcollins/hmms-spring2013.pdf), [video 1](https://youtu.be/-ngfOZz8yK0), [video 2](https://youtu.be/Tjgb-yQOg54), [video 3](https://youtu.be/aaa5Qoi8Vco), [video 4](https://youtu.be/4pKWIDkF_6Y)       \n","- [MEMMs and CRFs](https://github.com/dccuchile/CC6205/blob/master/slides/NLP-CRF.pdf): [notes 1](http://www.cs.columbia.edu/~mcollins/crf.pdf), [notes 2](http://www.cs.columbia.edu/~mcollins/fb.pdf), [video 1](https://youtu.be/qlI-4lSUDkg), [video 2](https://youtu.be/PLoLKQwkONw), [video 3](https://youtu.be/ZpUwDy6o28Y)\n","- [Convolutional Neural Networks](https://github.com/dccuchile/CC6205/blob/master/slides/NLP-CNN.pdf): [video](https://youtu.be/lLZW5Fn40r8)\n","- [Recurrent Neural Networks](https://github.com/dccuchile/CC6205/blob/master/slides/NLP-RNN.pdf): [video 1](https://youtu.be/BmhjUkzz3nk), [video 2](https://youtu.be/z43YFR1iIvk), [video 3](https://youtu.be/7L5JxQdwNJk)"]},{"cell_type":"markdown","metadata":{"id":"bWXD3D7RYKJ-"},"source":["# Hidden Markov Models (HMM), Maximum Entropy Markov Models (MEMM) and Conditional Random Field(CRF)\n","\n","### Pregunta 1 (1 pt)\n","Para un problema de POS tagging se define el conjunto de etiquetas $S = \\{ \\text{DET}, \\text{NOUN}, \\text{VERB}, \\text{ADP} \\}$ y se tiene un Hidden Markov Model con los siguientes par√°metros estimados a partir de un corpus de entrenamiento:\n","\n","\\begin{equation}\n","\\begin{split}\n","q(\\text{NOUN}| \\text{ VERB}, \\text{DET}) &= 0.3 \\\\\n","q(\\text{NOUN}|\\ w, \\text{DET}) &= 0 \\qquad \\forall w \\in S, w \\neq \\text{VERB} \\\\\n","q(\\text{DET}| \\text{ VERB}, \\text{NOUN}) &= 0.4 \\\\\n","q(\\text{DET}|\\ w, \\text{NOUN}) &= 0 \\qquad \\forall w \\in S, w \\neq \\text{VERB} \\\\\n","e(the|\\text{ DET}) &= 0.5 \\\\\n","e(pasta|\\text{ NOUN}) &= 0.6\n","\\end{split}\n","\\end{equation}\n","\n","Luego para la oraci√≥n: `the man is pouring sauce on the pasta`, se tiene una tabla de programaci√≥n din√°mica con los siguientes valores:\n","\\begin{equation}\n","\\begin{split}\n","\\pi(7,\\text{DET},\\text{DET})&=0.1\\\\\n","\\pi(7,\\text{NOUN},\\text{DET})&=0.2\\\\\n","\\pi(7,\\text{VERB},\\text{DET})&=0.01\\\\\n","\\pi(7,\\text{ADP},\\text{DET})&=0.5\n","\\end{split}\n","\\end{equation}\n","\n","Con esta informaci√≥n, calcule el valor de $\\pi(8,\\text{DET},\\text{NOUN})$. Puede dejar el resultado expresado como una fracci√≥n.\n"]},{"cell_type":"markdown","metadata":{"id":"5EzgysW9kGi-"},"source":["**Respuesta**\n","\\begin{equation}\n","\\begin{split}\n","\\pi(8,\\text{DET},\\text{NOUN}) &= \\max_{w\\in S_{6}} \\big(\\pi(7, w, \\text{DET}) \\times q(\\text{NOUN}|w,\\text{DET}) \\times e(\\text{pasta}|\\text{NOUN})\\big)\\\\\n","&= \\pi(7, \\text{VERB}, \\text{DET}) \\times q(\\text{NOUN}|\\text{VERB},\\text{DET}) \\times e(\\text{pasta}|\\text{NOUN})\\\\\n","&= 0.01 \\times 0.3 \\times 0.6 \\\\\n","&= 0.0018\n","\\end{split}\n","\\end{equation}\n"]},{"cell_type":"markdown","metadata":{"id":"oiwJb_vmkKLZ"},"source":["### Pregunta 2 (0.5 pts)\n","Comente  sobre las similitudes o diferencias entre los HMMs, MEMMs y CRFs. Para esto, responda las siguientes preguntas.\n","\n","#### 2.1. ¬øPara qu√© tipo de tarea sirven? D√© dos ejemplo de este tipo de tarea y descr√≠balos brevemente. (0.1 pts)\n","\n","**Respuesta:** Escriba su respuesta aqu√≠\n","\n","#### 2.2. ¬øQu√© modelos usan features? ¬øQu√© ventajas conlleva esto? (0.1 pts)\n","\n","**Respuesta:** Escriba su respuesta aqu√≠\n","\n","#### 2.3. ¬øC√≥mo maneja cada uno de los modelos las palabras con baja frecuencia en el set de train? (0.1 pts)\n","\n","**Respuesta:** Escriba su respuesta aqu√≠\n","\n","#### 2.4. ¬øQu√© le permite a los CRF realizar decisiones globales? ¬øQu√© diferencia con respecto a los MEMMs permite lograr esto? ¬øPor qu√© los HMMs tampoco son capaces de tomar decisiones globales? (0.1 pts)\n","\n","**Respuesta:** Escriba su respuesta aqu√≠\n","\n","#### 2.5 Dado una secuencia de $x_1, ..., x_m$ ¬øCu√°ntas posibles secuencias de etiquetas se pueden generar para un conjunto de etiquetas $S$ con $|S|=k$ ? ¬øAnalizarlas todas ser√≠a computacionalmente tratable? (0.1 pts)\n","\n","**Respuesta:** Escriba su respuesta aqu√≠"]},{"cell_type":"markdown","metadata":{"id":"P9h5ow8OWF7y"},"source":["**Respuestas**\n","#### Problemas para los que sirven:\n","Problemas que producen como salida una secuencia de etiquetas, a partir de una secuencia de entrada. Estos problemas con conocidos como *sequence labeling* y dos ejemplos de problemas de este tipo son:\n","- Named Entity Recognition (NER): Tiene como objetivo localizar y clasificar en categor√≠as predefinidas, como personas, organizaciones, lugares, expresiones de tiempo y cantidades, las entidades encontradas en el texto de input.\n","- Part-of-Speech (POS) Tagging: El objetivo es generar un secuencia de etiquetas que representan la categor√≠a gramatical de cada una de las palabras del texto de input.\n","\n","#### Modelos que usan features, ventajas:\n","Los modelos que usan features son MEMMs y CRF. Son modelos discriminativos mientras que los HMMs son modelos generativos. Los modelos discriminativos modelan directamente la probabilidad condicional utilizando un modelo parametrizado, minetras que los generativos utilizan solo la probabilidad conjunta.\n","\n","#### Manejo de las palabras con baja frecuencia:\n","En lose HMMs se reemplazan las palabras poco frecuentes por categor√≠as. Para esto, se divide el vocabulario en dos subconjuntos mediante un umbral de frecuencia: uno con las palabras frecuentes y otro con las poco frecuentes. Luego se convierten las poco frecuentes a un conjunto fijo de categor√≠as, por ejemplo, las fechas, los numeros y los nombres.\n","En la fase de testing, las palabras desconocidas las podemos llevar a estas categorias en vez de solo usar el token **unk**.\n","Esto trae como ventaja una mejora en las propiedades de generalizacion del modelo.\n","\n","En los MEMMs lo que tenemos son funciones parametrizadas para los cuales se aprenden pesos. Dado esto, el input se trata como un vector de caracteristicas (features).\n","Los inputs de los MEMMs incluyen la etiqueta. Esto tiene como ventaja que perimite codificar relaciones m√°s directas entre la etiqueta y el input.\n","Estas relaciones se determinan mediante el uso de $\\phi(\\cdot, \\cdot)$\n","\n","#### Decisiones globales de los CRFs, diferencias con respecto a los HMMs y MEMMs:\n","En los CRFs la normalizaci√≥n es global, mientras que en los MEMMs la normalizaci√≥n en local. Esto hace que entrenar una MEMMs es menos complicado que entrenar los CRFs.\n","\n","La gran ventaja de CRFs sobre MEMMs es que puede resolver un problema que se llama label bias. Este problema se da porque para algunas configuraciones de las etiquetas las MEMMs pueden ignorar informacion importante del contexto al realizar decisiones independientes en cada paso. Esto puede probocar una asignaci√≥n erronea de la etiqueta."]},{"cell_type":"markdown","metadata":{"id":"ClRAHR95Y8aB"},"source":["# Convolutional Neural Networks\n","### Pregunta 3 (1 pt)\n","\n","Considere la frase $w_{1..7}=$ `El agua moja y el fuego quema` $=[El, agua, moja, y, el, fuego, quema]$.\n","\n","La siguiente matriz de embeddings, donde la i-√©sima fila corresponde al vector de embedding de la i-√©sima palabra, ordenadas seg√∫n aparecen en la frase. (vectores de largo 2).\n","\\begin{equation}\n","E = \\begin{pmatrix}\n","2 & 2\\\\\n","0 & -2\\\\\n","0 & 1\\\\\n","-2 & 1\\\\\n","1 & 0\\\\\n","-1 & 1\\\\\n","1 & 1\n","\\end{pmatrix}\n","\\end{equation}\n","\n","Los siguientes 3 filtros\n","\\begin{equation}\n","U = \\begin{pmatrix}\n","-1 & 1 & 0\\\\\n","1 & 1 & 0\\\\\n","0 & 0 & -1\\\\\n","1 & -1 & -1\\\\\n","-1 & -1 & 1\\\\\n","1 & 0 & -1\n","\\end{pmatrix}\n","\\end{equation}\n","\n","Y la funci√≥n de activaci√≥n\n","\\begin{equation}\n","tanh = \\frac{e^{2x} - 1}{e^{2x} + 1}\n","\\end{equation}\n","\n","Usando estos param√°tros escriba los pasos para calcular la representaci√≥n (vector) resultante de aplicar la operaci√≥n de convoluci√≥n (sin padding) + max pooling. ¬øDe qu√© tama√±o ser√≠a la ventana que debemos usar?"]},{"cell_type":"markdown","metadata":{"id":"SlQ30Arkq0u4"},"source":["**Respuesta**\n","Dado que la matriz de filtro tiene 6 filas y los embedigs son vectores de largo 2, concluimos que la ventana es de tama√±o 3. Por tanto estamos usando n-gramas de 3 palabras.\n","\n","\\begin{equation}\n","\\begin{split}\n","w_{1..3} &=[El, agua, moja] &= \\big(2,2,0,-2,0,1\\big)\\\\\n","w_{2..4} &=[agua, moja, y]  &= \\big(0,-2,0,1,-2,1\\big)\\\\\n","w_{3..5} &=[moja, y, el]    &= \\big(0,1,-2,1,1,0\\big)\\\\\n","w_{4..6} &=[y, el, fuego]   &= \\big(-2,1,1,0,-1,1\\big)\\\\\n","w_{5..7} &=[el, fuego, quema] &= \\big(1,0,-1,1,1,1\\big)\\\\\n","\\end{split}\n","\\end{equation}\n","\n","\\\n","\n","\\begin{equation}\n","\\begin{split}\n","[[-1  6  1]\n"," [ 2 -1 -4]\n"," [ 1 -1  2]\n"," [ 5  0 -3]\n"," [ 0 -1  0]]\n","u_{1..3} &=\\text{tanh}(w_{1..3} \\cdot U) &= \\text{tanh}\\big((-1,6,1)\\big)&=(-0.76159416&,  0.99998771&,  0.76159416&)\\\\\n","u_{2..4} &=\\text{tanh}(w_{2..4} \\cdot U) &= \\text{tanh}\\big((1,-1,-4)\\big)&=(0.96402758&, -0.76159416&, -0.9993293&)\\\\\n","u_{3..5} &=\\text{tanh}(w_{3..5} \\cdot U) &= \\text{tanh}\\big((1,-1,2)\\big)&=(0.76159416&, -0.76159416&,  0.96402758&)\\\\\n","u_{4..6} &=\\text{tanh}(w_{4..6} \\cdot U) &= \\text{tanh}\\big((5,0,-3)\\big)&=(0.9999092&,   0.0&,         -0.99505475&)\\\\\n","u_{5..7} &=\\text{tanh}(w_{5..7} \\cdot U) &= \\text{tanh}\\big((0,-1,0)\\big)&=(0.0&,         -0.76159416&,  0.0        &)\\\\\n","\\end{split}\n","\\end{equation}\n","\n","\\\n","\n","\\begin{equation}\n","\\begin{split}\n","Y &=\\text{max-pool}\\big((u_{1..3},u_{2..4},u_{3..5},u_{4..6},u_{5..7})\\big) \\\\\n","  &=(0.9999092,  0.99998771, 0.96402758)\\\\\n","\\end{split}\n","\\end{equation}"]},{"cell_type":"code","metadata":{"id":"m63_M8MQFLDB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1654901167426,"user_tz":240,"elapsed":8,"user":{"displayName":"Ignacio Meza","userId":"07738957670140287594"}},"outputId":"29de4971-e1b2-4093-bdd8-70d994b90610"},"source":["import numpy as np\n","\n","U = np.array([[-1, 1, 0],\n","              [1,1,0],\n","              [0,0,-1],\n","              [1,-1,-1],\n","              [-1,-1,1],\n","              [1,0,-1]])\n","W = np.array([[2,2,0,-2,0,1],\n","              [0,-2,0,1,-2,1],\n","              [0,1,-2,1,1,0],\n","              [-2,1,1,0,-1,1],\n","              [1,0,-1,1,1,1]])\n","\n","H = np.matmul(W, U)\n","H1 = np.tanh(H)\n","\n","print(H)\n","print(H1)\n","print('result: ', np.max(H1, axis=0))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[-1  6  1]\n"," [ 2 -1 -4]\n"," [ 1 -1  2]\n"," [ 5  0 -3]\n"," [ 0 -1  0]]\n","[[-0.76159416  0.99998771  0.76159416]\n"," [ 0.96402758 -0.76159416 -0.9993293 ]\n"," [ 0.76159416 -0.76159416  0.96402758]\n"," [ 0.9999092   0.         -0.99505475]\n"," [ 0.         -0.76159416  0.        ]]\n","result:  [0.9999092  0.99998771 0.96402758]\n"]}]},{"cell_type":"markdown","metadata":{"id":"U0et78Z4oKIq"},"source":["# Recurrent Neural Networks\n","### Pregunta 4 (1 pt)\n","Usando los embeddings de dos dimensiones de la pregunta anteror, la oraci√≥n `el fuego quema` la podemos representar por una secuencia de vectores $(\\vec{x}_1,\\vec{x}_2,\\vec{x}_3)$, con $\\vec{x}_i \\in \\mathbb{R}^{d_x}$ y $d_x=2$.\n","\n","Tenemos una red recurrente *Elman* definidad como:\n","\\begin{equation}\n","\\begin{split}\n","\\vec{s}_i &= R_{SRNN}\\left (\\vec{x}_i, \\vec{s}_{i-1}\\right ) = g \\left (\\vec{s}_{i-1}W^s + \\vec{x}_i W^x + \\vec{b}\\right ) \\\\\n","\\vec{y}_i &= O_{SRNN}\\left(\\vec{s}_i\\right) = \\vec{s}_i \\\\\n","\\end{split}\n","\\end{equation}\n","donde\n","\\begin{equation}\n","\\vec{s}_i, \\vec{y}_i \\in \\mathbb{R}^{d_s}, \\quad W^x \\in \\mathbb{R}^{d_x \\times d_s}, \\quad W^s \\in \\mathbb{R}^{d_s \\times d_s}, \\quad \\vec{b} \\in \\mathbb{R}^{d_s},\n","\\end{equation}\n","y los vectores de estado $s_i$ son de tres dimensiones, $ds= 3$.\n","\n","Sea\n","\\begin{equation}\n","\\begin{split}\n","\\vec{s}_0 &= [0,0,0]\\\\\n","W^x &= \\begin{pmatrix}\n","0 &  0 & 1\\\\\n","1 & -1 & 0\n","\\end{pmatrix} \\\\\n","W^s &= \\begin{pmatrix}\n","1 & 0 &  1\\\\\n","0 & 1 & -1\\\\\n","1 & 1 &  1\n","\\end{pmatrix} \\\\\n","\\vec{b} &= [0, 0, 0] \\\\\n","g(x) &= ReLu(x) = max(0, x)\n","\\end{split}\n","\\end{equation}\n","\n","<br>\n","\n","Calcule manualmente los valores de los vectores $\\vec{s}_1, \\vec{s}_2,\\vec{s}_3$ y de $\\vec{y}_1, \\vec{y}_2,\\vec{y}_3$."]},{"cell_type":"markdown","metadata":{"id":"fim2W8JioPhL"},"source":["**Respuesta**\n","\n","\\begin{split}\n","    \\vec{s}_1 &= \\text{ReLu}(\\vec{s_0}W^s + \\vec{x_0}W^x+\\vec{b}) \\\\\n","              &= \\text{ReLu}([0,0,0]\n","              \\begin{pmatrix}\n","                1 & 0 &  1\\\\\n","                0 & 1 & -1\\\\\n","                1 & 1 &  1\n","              \\end{pmatrix}   + [1,0]\n","              \\begin{pmatrix}\n","                0 &  0 & 1\\\\\n","                1 & -1 & 0\n","              \\end{pmatrix} + [0,0,0]) \\\\\n","              &= \\text{ReLu}([0,0,1]) \\\\\n","              &= [0,0,1]\n","\\end{split}\n","\n","\\\n","\n","\\begin{split}\n","    \\vec{s}_2 &= \\text{ReLu}(\\vec{s_1}W^s + \\vec{x_2}W^x+\\vec{b}) \\\\\n","              &= \\text{ReLu}([0,0,1]\n","              \\begin{pmatrix}\n","                1 & 0 &  1\\\\\n","                0 & 1 & -1\\\\\n","                1 & 1 &  1\n","              \\end{pmatrix}   + [-1,1]\n","              \\begin{pmatrix}\n","                0 &  0 & 1\\\\\n","                1 & -1 & 0\n","              \\end{pmatrix}+[0,0,0]) \\\\\n","              &= \\text{ReLu}([2,0,0]) \\\\\n","              &= [2,0,0] \\\\\n","\\end{split}\n","\n","\\\n","\n","\\begin{split}\n","    \\vec{s}_3 &= \\text{ReLu}(\\vec{s_2}W^s + \\vec{x_3}W^x+\\vec{b}) \\\\\n","              &= \\text{ReLu}([2,0,0]\n","              \\begin{pmatrix}\n","                1 & 0 &  1\\\\\n","                0 & 1 & -1\\\\\n","                1 & 1 &  1\n","              \\end{pmatrix}   + [1,1]\n","              \\begin{pmatrix}\n","                0 &  0 & 1\\\\\n","                1 & -1 & 0\n","              \\end{pmatrix}+[0,0,0])  \\\\\n","              &= \\text{ReLu}([3,-1,3]) \\\\\n","              &= [3,0,3]\n","\\end{split}"]},{"cell_type":"code","metadata":{"id":"EfcOlD0IOdgJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1654901167426,"user_tz":240,"elapsed":6,"user":{"displayName":"Ignacio Meza","userId":"07738957670140287594"}},"outputId":"6865bf3c-ec63-4e55-bd06-3dd25b768ac8"},"source":["import numpy as np\n","x  = np.array([[1,0], [-1,1], [1,1]])\n","s = np.array([0,0,0])\n","Ws = np.array([[1,0,1],[0,1,-1],[1,1,1]])\n","Wx = np.array([[0,0,1],[1,-1,0]])\n","b = np.array([0,0,0])\n","for xi in x:\n","  print('\\nstep for: ', xi)\n","  print(np.matmul(s,Ws))\n","  print(np.matmul(xi,Wx))\n","  s = np.matmul(s,Ws) + np.matmul(xi,Wx) + b\n","  print(s)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","step for:  [1 0]\n","[0 0 0]\n","[0 0 1]\n","[0 0 1]\n","\n","step for:  [-1  1]\n","[1 1 1]\n","[ 1 -1 -1]\n","[2 0 0]\n","\n","step for:  [1 1]\n","[2 0 2]\n","[ 1 -1  1]\n","[ 3 -1  3]\n"]}]},{"cell_type":"markdown","metadata":{"id":"W4rAT6ELxRZW"},"source":["### Pregunta 5 (0.5 pts)\n","¬øDe qu√© forma las RNN y las CNN logran aprender representaciones espec√≠ficas\n","para la tarea objetivo? Compare la forma en que las RNN y las CNN aprenden con los modelos que usan *features* dise√±adas manualmente."]},{"cell_type":"markdown","metadata":{"id":"b6AXbQSgA_t8"},"source":["**Respuesta**\n","\n","Las RNN preservan la estructura a lo largo de la sequencia, codificando los vectores de la secuencia (embeddings) en un solo vector. En el caso de las tareas de sequence labeling, podemos usar los vectores de salida temporales (para cada uno de las posibles subsecuencias prefijo del texto), pas√°ndolos por un modelo que los clasifique seg√∫n el label.\n","\n","Las RNN y las CNN no necesitan que se dise√±en los features manualmente. Ellas son capaces de aprender los features directamente a partir de las propiedades estad√≠sticas de la secuencia."]},{"cell_type":"markdown","source":["# Pregunta 6: Redes Neuronales con Pytorch (3 puntos) üí¨\n","\n","<center>\n","<img src=\"https://www.anda.cl/wp-content/uploads/2021/03/0_5vNAtimPjYQr4W72.gif\" alt=\"chatbot\" width=\"400\">\n","</center>"],"metadata":{"id":"FRJkBpjWyHnb"}},{"cell_type":"markdown","source":["En esta secci√≥n de la tarea deber√°n implementar un Chatbot que sea capaz de generar una conversaci√≥n *‚Äúb√°sica‚Äù* utilizando un dataset de *Star Wars*. **El objetivo** de esta pregunta es que puedan aplicar lo aprendido sobre redes neuronales utilizando Pytorch en un ejemplo pr√°ctico.  Durante el desarrollo, se espera que puedan dise√±ar un bot (que tendr√° por atr√°s un clasificador) que sea capaz de clasificar diferentes etiquetas, cosa que una vez identificada la etiqueta entregue una respuesta acorde a lo preguntado.\n","\n","**Aviso:** Antes de comenzar con una descripci√≥n mas profunda de esta secci√≥n, les recomendamos que visualicen y se familiaricen con el dataset entregado, de esta forma comprender√°n mejor la descripci√≥n del enunciado (aqu√≠ una peque√±a ayudita üÜò)."],"metadata":{"id":"GEla92bUymrQ"}},{"cell_type":"code","source":["import pandas as pd\n","\n","example_data = pd.read_json('https://raw.githubusercontent.com/dccuchile/CC6205/master/assignments/star_wars_chatbot.json')\n","print(\"Cantidad de tags: \", example_data['intents'].shape[0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0eKOGlMs3Dx-","executionInfo":{"status":"ok","timestamp":1685721299498,"user_tz":240,"elapsed":1372,"user":{"displayName":"Gabriel Iturra-Bocaz","userId":"02319919045117626989"}},"outputId":"1104656f-a980-4bb5-af43-7bb8affcbb52"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Cantidad de tags:  16\n"]}]},{"cell_type":"markdown","source":["A continuaci√≥n, ejemplos del contenido del primer registro:"],"metadata":{"id":"V-6fCE5fHkNS"}},{"cell_type":"code","source":["example_data['intents'][0]['patterns']"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"axsi27BpHGOx","executionInfo":{"status":"ok","timestamp":1685721314538,"user_tz":240,"elapsed":480,"user":{"displayName":"Gabriel Iturra-Bocaz","userId":"02319919045117626989"}},"outputId":"ab151008-83b5-482c-d995-ad1eea0e084e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Hi',\n"," 'Hey',\n"," 'How are you',\n"," 'Is anyone there?',\n"," 'Hello',\n"," 'Good day',\n"," \"What's up\",\n"," 'Yo!',\n"," 'Howdy',\n"," 'Nice to meet you.']"]},"metadata":{},"execution_count":2}]},{"cell_type":"code","source":["example_data['intents'][0]['responses']"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OV0vGdwoHeg3","executionInfo":{"status":"ok","timestamp":1685721319064,"user_tz":240,"elapsed":4,"user":{"displayName":"Gabriel Iturra-Bocaz","userId":"02319919045117626989"}},"outputId":"4d937926-f601-4696-fe7c-e50dc77b8da5"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Hey',\n"," 'Hello, thanks for visiting.',\n"," 'Hi there, what can I do for you?',\n"," 'Hi there, how can I help?',\n"," 'Hello, there.',\n"," 'Hello Dear',\n"," 'Ooooo Hello, looking for someone or something?',\n"," 'Yes, I am here.',\n"," 'Listening carefully.',\n"," 'Ok, I am with you.']"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["example_data['intents'][0]['tag']"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"0BnYez1oGtx3","executionInfo":{"status":"ok","timestamp":1685721321470,"user_tz":240,"elapsed":6,"user":{"displayName":"Gabriel Iturra-Bocaz","userId":"02319919045117626989"}},"outputId":"a2d3cc6c-5c51-4b8f-f50f-dd65d604aa34"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'greeting'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":4}]},{"cell_type":"markdown","source":["Del dataset cargado podemos notar que este viene en un formato `JSON`, por lo que sus datos est√°n almacenados en diccionarios. Las llaves de los diccionarios no son aleatorias y estos nos sirven para identificar puntos relevantes en el desarrollo del bot. A continuaci√≥n, se realiza una peque√±a descripci√≥n de las llaves:\n","\n","- `patterns`: Almacena los patrones con los que entrenaremos el modelo üòÆ, en otras palabras, es el corpus de entrenamiento que contiene solo preguntas o expresiones que deber√° responder el bot.\n","- `responses`: Son las respuestas üôã relacionadas a los `patterns`, estas las utilizaremos en una etapa posterior a la clasificaci√≥n, para dar una respuesta aleator√≠a al usuario.\n","- `tag`: Son las labels con las que entrenaremos nuestro modelo üíª.\n","\n","En s√≠ntesis, las `keys` relevantes para el entrenamiento de nuestra red neuronal ser√°n `patterns` (corpus) y `tag` (etiquetas)."],"metadata":{"id":"v6BvAWCw3zPM"}},{"cell_type":"markdown","source":["#### Explicaci√≥n de la tarea a realizar:"],"metadata":{"id":"KlOAdMjSSzNN"}},{"cell_type":"markdown","source":["**Explicaci√≥n de la tarea a realizar**: Implemente una Class llamada `CNNClassifier` que sea capaz de entrenar un modelo de texto a trav√©s de una red neuronal Feed Forward y una arquitectura convolucional (CNN 1D) [`torch.nn.Conv1d`](https://pytorch.org/docs/stable/generated/torch.nn.Conv1d.html#conv1d) . Para el dise√±o de las redes tienen completa libertad, pero se le aconseja que se gu√≠en de la √∫ltima auxiliar para la construcci√≥n. Es **important√≠simo** que el modelo a crear posea una capa de `Embedding` que se genere en base al entrenamiento del modelo. Creado el modelo, construya una funci√≥n batch para cargar los datos de entrenamiento del modelo.\n","\n","Construido el modelo, compare los resultados obtenidos para una red feed forward y una cnn. Para la comprobaci√≥n de sus resultados ejecute el chatbot y pruebelo, ¬øqu√© configuraci√≥n tiene mejores resultados?, ¬øa qu√© se deberan estos resultados?\n","\n","Ojo que un ejemplo de prueba con el chatbot puede ser (agregue mas preguntas ud):\n","\n","```\n","Let's chat! (type 'finish_chat' to finish the chat)\n","You: hi\n","GA-97: Yes, I am here.\n","You: can you tell me a joke?\n","GA-97: Have you tried the gluten-free Wookiee treats? No, but I heard they are a little Chewy.\n","```\n","\n","\n","**Igual [mucho texto](https://i0.wp.com/elgeneracionalpost.com/wp-content/uploads/2020/07/mucho-texto.jpg?fit=1280%2C720&ssl=1).... En resumen, ¬øQu√© se solicita?:**\n","\n","- [ ] Dise√±ar una red neuronal Feed Forward.\n","- [ ] Dise√±ar un red convolucional.\n","- [ ] Crear el m√©todo forward de la clase `CNNClassifier`.\n","- [ ] Crear la funci√≥n BATCH.\n","- [ ] Probar el modelo y comparar los resultados obtenidos con la red Feed Forward y la red CNN. Comente sus resultados de forma cualitativa, se√±alando con qu√© tipo de red obtuvo mejores resultados con el chatbot.\n","\n","**Nota-1:** El modelo creado debe tener la opci√≥n de entrenar a traves de una feed forward y una CNN. Esto no significa que entrenar√° una FF y una CN, el modelo deber√° recibir un booleano que especifique que tipo de red utilizar√°.\n","\n","**Nota-2:** El dataset se descargar√° autom√°ticamente en la secci√≥n `Carga de Dataset üìö`, no os preocup√©is."],"metadata":{"id":"9yGApnWVI4cO"}},{"cell_type":"markdown","source":["#### Pasemos al C√≥digo ü¶æ\n","\n","Esqueleto propuesto (se **RECOMIENDA** que cambien **SOLO** la red neuronal y la funci√≥n Batch) ü¶¥:"],"metadata":{"id":"a4bKfAdEy3oD"}},{"cell_type":"markdown","source":["##### Instalamos librerias necesarias e importamos üòÄ"],"metadata":{"id":"RUwxivx2MpMV"}},{"cell_type":"code","source":["%%capture\n","!pip install torch==1.8.0+cu111 -f https://download.pytorch.org/whl/torch_stable.html\n","!pip install torchtext==0.9.0"],"metadata":{"id":"TjSZkBsk1H4f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import sys\n","import json\n","import torch\n","import random\n","from random import choice\n","from torchtext.datasets import AG_NEWS\n","from torchtext.data.utils import get_tokenizer\n","from torchtext.vocab import build_vocab_from_iterator\n","\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader\n","\n","from torch.optim import SGD, lr_scheduler\n","from torch.utils.data import DataLoader\n","from torch.autograd import Variable\n","\n","from itertools import zip_longest\n","\n","import plotly.express as px\n","\n","import numpy as np\n","import nltk\n","from nltk.stem.porter import PorterStemmer"],"metadata":{"id":"RfZ6SL-Q1Kwd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### Carga de Dataset üìö"],"metadata":{"id":"oj-Epe7XJLrL"}},{"cell_type":"code","source":["# we obtain the dataset\n","!wget 'https://raw.githubusercontent.com/dccuchile/CC6205/master/assignments/star_wars_chatbot.json'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hvlLqYRrVN6l","executionInfo":{"status":"ok","timestamp":1685721350904,"user_tz":240,"elapsed":803,"user":{"displayName":"Gabriel Iturra-Bocaz","userId":"02319919045117626989"}},"outputId":"278e1647-4822-4530-80a4-3cc6fc38b5d4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--2023-06-02 15:57:18--  https://raw.githubusercontent.com/dccuchile/CC6205/master/assignments/star_wars_chatbot.json\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 14469 (14K) [text/plain]\n","Saving to: ‚Äòstar_wars_chatbot.json‚Äô\n","\n","\rstar_wars_chatbot.j   0%[                    ]       0  --.-KB/s               \rstar_wars_chatbot.j 100%[===================>]  14.13K  --.-KB/s    in 0s      \n","\n","2023-06-02 15:57:18 (89.4 MB/s) - ‚Äòstar_wars_chatbot.json‚Äô saved [14469/14469]\n","\n"]}]},{"cell_type":"code","source":["# Load the dataset using json\n","with open('star_wars_chatbot.json', 'r') as f:\n","    dataset = json.load(f)\n","\n","# Create a vocab with the dataset and get the number of classes that have\n","tokenizer = get_tokenizer(\"basic_english\")\n","vocab = build_vocab_from_iterator(tokenizer(x) for list_words in dataset['intents'] for x in list_words['patterns'])\n","num_classes = len(dataset['intents'])\n","\n","# Define a list with the labels\n","labels = sorted(set([tag for tag in [intents['tag'] for intents in dataset['intents']]]))\n","# Define a train_list where we can find the info in the format: [(tag_0, text_0)...,(tag_n-1, text_n-1)]\n","train_list = [(labels.index(intents['tag']), text) for intents in dataset['intents'] for text in intents['patterns']]"],"metadata":{"id":"MbbIsFUG1TXW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### Creaci√≥n del modelo (2 puntos en total)"],"metadata":{"id":"a52SUNKPJQxi"}},{"cell_type":"code","source":["import torch.nn.functional as F\n","\n","class CNNClassifier(nn.Module):\n","    def __init__(self, vocab_size, embed_dim=32, num_classes=10,\n","                 use_cnn=False, cnn_pool_channels=24, cnn_kernel_size=3):\n","      super().__init__()\n","      self.use_cnn = use_cnn\n","\n","      if use_cnn:\n","        # capa de embedding\n","        self.embedding = nn.Embedding(vocab_size, embed_dim)\n","\n","        # capa de convoluci√≥n\n","        self.conv = nn.Conv1d(\n","            in_channels=1,\n","            out_channels=cnn_pool_channels,\n","            kernel_size=cnn_kernel_size * embed_dim,\n","            stride=embed_dim,\n","        )\n","\n","        fc_in_size = cnn_pool_channels\n","      else:\n","        # capa de embedding, en este caso usamos EmbeddingBag\n","        # por lo que necesitaremos los offsets del batch en el forwards\n","        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=True)\n","\n","        fc_in_size = embed_dim\n","\n","      # capa lineal\n","      self.fc = nn.Linear(fc_in_size, num_classes)\n","\n","      self.init_weights()\n","\n","    def init_weights(self):\n","      initrange = 0.5\n","      self.embedding.weight.data.uniform_(-initrange, initrange)\n","      self.fc.weight.data.uniform_(-initrange, initrange)\n","      self.fc.bias.data.zero_()\n","\n","    def forward(self, text, offsets):\n","      if self.use_cnn:\n","        # preparamos el input de la capa de embeddings a partir de text y offsets\n","        # (N x longest_text)\n","        text = torch.tensor(\n","            list(\n","                zip(\n","                    *zip_longest(\n","                        *([text[o:offsets[i+1]] for i, o in enumerate(offsets[:-1])] + [text[offsets[-1]:len(texts)]]),\n","                        fillvalue=vocab[\"<pad>\"]\n","                    )\n","                )\n","            )\n","        ).to(text.device)\n","\n","        # (N x longest_text x embed_dim)\n","        h = self.embedding(text)\n","\n","        # (N x pool_channels)\n","        h = h.view(h.size(0), 1, -1)\n","        h = torch.relu(self.conv(h))\n","        h = h.mean(dim=2)\n","      else:\n","        # (N x embed_dim)\n","        h = self.embedding(text, offsets)\n","\n","      # (N x num_classes)\n","      output = self.fc(h)\n","      return F.log_softmax(output, dim=1)"],"metadata":{"id":"n-vQ24tMJG5H"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Construya el modelo\n","import torch.nn.functional as F\n","class CNNClassifier(nn.Module):\n","    def __init__(self, vocab_size, embed_dim=32, num_classes=16,\n","                 use_cnn=False, cnn_pool_channels=24, cnn_kernel_size=3):\n","      super().__init__()\n","\n","      self.use_cnn = use_cnn\n","      # capa de embedding\n","      #self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, mode=\"mean\")\n","      self.embedding = nn.Embedding(vocab_size, embed_dim, 1)\n","      if use_cnn:\n","        # capa de convolucion\n","        self.conv = nn.Conv1d(\n","            in_channels=1,\n","            out_channels=cnn_pool_channels,\n","            kernel_size=cnn_kernel_size * embed_dim,\n","            stride=embed_dim,\n","        )\n","        self.pool = nn.MaxPool1d(3)\n","        #fc_in_size = cnn_pool_channels\n","        self.conv2 = nn.Conv1d(cnn_pool_channels, cnn_pool_channels, 1)\n","        fc_in_size = cnn_pool_channels\n","      else:\n","        fc_in_size = embed_dim\n","      # capas lineales\n","      self.fc1 = nn.Linear(fc_in_size, 42)\n","      self.fc2 = nn.Linear(42, num_classes)\n","\n","      self.init_weights()\n","\n","\n","    def init_weights(self):\n","      # Esto puede ser util para inicializar los pesos\n","      initrange = 0.5\n","      self.embedding.weight.data.uniform_(-initrange, initrange)\n","      self.fc1.weight.data.uniform_(-initrange, initrange)\n","      self.fc1.bias.data.zero_()\n","      self.fc2.weight.data.uniform_(-initrange, initrange)\n","      self.fc2.bias.data.zero_()\n","\n","    def forward(self, text, offsets):\n","      text = torch.tensor(\n","          list(\n","              zip(\n","                  *zip_longest(\n","                      *([text[o:offsets[i+1]] for i, o in enumerate(offsets[:-1])] + [text[offsets[-1]:len(texts)]]),\n","                      fillvalue=vocab[\"<pad>\"]\n","                  )\n","              )\n","          )\n","      ).to(text.device)\n","      h = self.embedding(text)\n","      #h = h.mean(dim=1)\n","      if self.use_cnn:\n","        h = h.view(h.size(0), 1, -1)\n","        h = torch.relu(self.conv(h))\n","        h = self.pool(h)\n","        h = torch.relu(self.conv2(h))\n","        h = h.mean(dim=2)\n","      else:\n","        h = h.mean(dim=1)\n","      h = F.relu(self.fc1(h))\n","      h = self.fc2(h)\n","      return h"],"metadata":{"id":"XVNKlTmU3-0B"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### Funci√≥n Batch üë∑ (0,5 puntos)"],"metadata":{"id":"dGN-T0JoJtmS"}},{"cell_type":"code","source":["# Define a function to load the batch.\n","def generate_batch(batch):\n","  label = torch.tensor([entry[0] for entry in batch])\n","  texts = [tokenizer(entry[1]) for entry in batch]\n","  offsets = [0] + [len(text) for text in texts]\n","  offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n","  big_text = torch.cat([torch.tensor([vocab.stoi[t] for t in text]) for text in texts])\n","  return big_text, offsets, label"],"metadata":{"id":"K1AZpXc7JxTa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### Entrenamiento ü•ä"],"metadata":{"id":"YChwpNrrNRBe"}},{"cell_type":"code","source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"GPU is avaible: {device}\")\n","\n","# Define the different inputs in our model\n","num_epochs = 5\n","BATCH_SIZE = 16\n","LR = 1e-1\n","INPUT_SIZE = len(vocab)\n","OUTPUT_SIZE = num_classes\n","USE_CNN = False\n","\n","# Define model, optimizer, loss and scheduler (Q: ¬øWhat is it?)\n","model = CNNClassifier(INPUT_SIZE, num_classes=OUTPUT_SIZE, use_cnn=USE_CNN).to(device)\n","optimizer = SGD(model.parameters(), lr=LR)\n","criterion = nn.CrossEntropyLoss().to(device)\n","scheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda=[lambda epoch: .9 ** (epoch // 10)])\n","\n","print(f'train: {len(train_list)} elements')\n","\n","# We train the model using the intents\n","loss_list= []\n","for epoch in range(1, num_epochs):\n","  train_loader = DataLoader(train_list, batch_size=BATCH_SIZE, collate_fn=generate_batch)\n","  model.train()\n","  total_loss = 0\n","  for i, (texts, offsets, cls) in enumerate(train_loader):\n","    texts = texts.to(device)\n","    offsets = offsets.to(device)\n","    cls = cls.to(device)\n","    optimizer.zero_grad()\n","    output = model(texts, offsets)\n","    loss = criterion(output, cls)\n","    total_loss += loss.item()\n","    loss.backward()\n","    optimizer.step()\n","\n","  loss_list.append(loss.item())\n","  sys.stdout.write('\\rEpoch: {0:03d} \\t iter-Loss: {1:.3f}'.format(epoch+1, loss.item()))\n","\n","print(f'final loss: {loss.item():.4f}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":416},"id":"L5eRWRD_J0Km","executionInfo":{"status":"error","timestamp":1685721462380,"user_tz":240,"elapsed":749,"user":{"displayName":"Gabriel Iturra-Bocaz","userId":"02319919045117626989"}},"outputId":"870f7160-cb53-4d49-e889-79ad13b86074"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["GPU is avaible: cuda\n","train: 97 elements\n"]},{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-fcf014c73af6>\u001b[0m in \u001b[0;36m<cell line: 22>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m   \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffsets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0mtexts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtexts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0moffsets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moffsets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    631\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 677\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    678\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-11-8f3aa93405da>\u001b[0m in \u001b[0;36mgenerate_batch\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0moffsets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtexts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0moffsets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moffsets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcumsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m   \u001b[0mbig_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstoi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtexts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mbig_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffsets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-11-8f3aa93405da>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0moffsets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtexts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0moffsets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moffsets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcumsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m   \u001b[0mbig_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstoi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtexts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mbig_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffsets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-11-8f3aa93405da>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0moffsets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtexts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0moffsets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moffsets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcumsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m   \u001b[0mbig_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstoi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtexts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mbig_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffsets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1612\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1614\u001b[0;31m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0m\u001b[1;32m   1615\u001b[0m             type(self).__name__, name))\n\u001b[1;32m   1616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'Vocab' object has no attribute 'stoi'"]}]},{"cell_type":"code","source":["# Plot de Entrenamiento\n","import plotly.express as px\n","fig = px.line(y=loss_list, x=np.arange(1,num_epochs), title=\"Training Loss\")\n","fig.update_layout(\n","    xaxis_title=\"Epochs\",\n","    yaxis_title=\"Loss\"\n","    )"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":542},"id":"Gqll-LbcJ4aU","executionInfo":{"status":"ok","timestamp":1654902538166,"user_tz":240,"elapsed":12,"user":{"displayName":"Ignacio Meza","userId":"07738957670140287594"}},"outputId":"40449568-d7e9-4178-8dde-a653f1a72c90"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["<html>\n","<head><meta charset=\"utf-8\" /></head>\n","<body>\n","    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n","        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"f511db33-526f-4258-9643-66aa551a5df0\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"f511db33-526f-4258-9643-66aa551a5df0\")) {                    Plotly.newPlot(                        \"f511db33-526f-4258-9643-66aa551a5df0\",                        [{\"hovertemplate\":\"x=%{x}<br>y=%{y}<extra></extra>\",\"legendgroup\":\"\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,573,574,575,576,577,578,579,580,581,582,583,584,585,586,587,588,589,590,591,592,593,594,595,596,597,598,599,600,601,602,603,604,605,606,607,608,609,610,611,612,613,614,615,616,617,618,619,620,621,622,623,624,625,626,627,628,629,630,631,632,633,634,635,636,637,638,639,640,641,642,643,644,645,646,647,648,649,650,651,652,653,654,655,656,657,658,659,660,661,662,663,664,665,666,667,668,669,670,671,672,673,674,675,676,677,678,679,680,681,682,683,684,685,686,687,688,689,690,691,692,693,694,695,696,697,698,699,700,701,702,703,704,705,706,707,708,709,710,711,712,713,714,715,716,717,718,719,720,721,722,723,724,725,726,727,728,729,730,731,732,733,734,735,736,737,738,739,740,741,742,743,744,745,746,747,748,749,750,751,752,753,754,755,756,757,758,759,760,761,762,763,764,765,766,767,768,769,770,771,772,773,774,775,776,777,778,779,780,781,782,783,784,785,786,787,788,789,790,791,792,793,794,795,796,797,798,799,800,801,802,803,804,805,806,807,808,809,810,811,812,813,814,815,816,817,818,819,820,821,822,823,824,825,826,827,828,829,830,831,832,833,834,835,836,837,838,839,840,841,842,843,844,845,846,847,848,849,850,851,852,853,854,855,856,857,858,859,860,861,862,863,864,865,866,867,868,869,870,871,872,873,874,875,876,877,878,879,880,881,882,883,884,885,886,887,888,889,890,891,892,893,894,895,896,897,898,899,900,901,902,903,904,905,906,907,908,909,910,911,912,913,914,915,916,917,918,919,920,921,922,923,924,925,926,927,928,929,930,931,932,933,934,935,936,937,938,939,940,941,942,943,944,945,946,947,948,949,950,951,952,953,954,955,956,957,958,959,960,961,962,963,964,965,966,967,968,969,970,971,972,973,974,975,976,977,978,979,980,981,982,983,984,985,986,987,988,989,990,991,992,993,994,995,996,997,998,999],\"xaxis\":\"x\",\"y\":[2.985321521759033,2.7076072692871094,2.4689910411834717,2.249636173248291,2.034414052963257,1.8309537172317505,1.6240392923355103,1.428620457649231,1.2506167888641357,1.0758605003356934,0.9233945608139038,0.8030738830566406,0.6722238063812256,0.581586480140686,0.5011048913002014,0.42500901222229004,0.3820588290691376,0.3261910378932953,0.2901454567909241,0.25456392765045166,0.23246429860591888,0.2063983678817749,0.18575379252433777,0.16849784553050995,0.15465232729911804,0.13917222619056702,0.12842117249965668,0.11930479109287262,0.10863425582647324,0.10058891773223877,0.09404101222753525,0.08769698441028595,0.08222596347332001,0.07661961764097214,0.07289440929889679,0.0680198222398758,0.06498338282108307,0.06074511259794235,0.0577024482190609,0.05444381386041641,0.05211540311574936,0.049455426633358,0.04741622507572174,0.04522383585572243,0.0431005097925663,0.040998294949531555,0.03949218615889549,0.03800136223435402,0.03645360469818115,0.03497355058789253,0.033826835453510284,0.03264454007148743,0.031686536967754364,0.030892565846443176,0.029976267367601395,0.0292484350502491,0.028398530557751656,0.02772427909076214,0.026988770812749863,0.02644871547818184,0.025810206308960915,0.025188028812408447,0.02461315132677555,0.024127785116434097,0.023649750277400017,0.02312990091741085,0.022747064009308815,0.02232537418603897,0.02196718566119671,0.02151518315076828,0.021199537441134453,0.020891845226287842,0.020518893375992775,0.020227113738656044,0.01985870487987995,0.019480107352137566,0.01918860897421837,0.018895037472248077,0.01844070851802826,0.018076442182064056,0.01766437478363514,0.017342939972877502,0.017031949013471603,0.016661541536450386,0.01633814163506031,0.01604701764881611,0.015665212646126747,0.015395843423902988,0.015166440978646278,0.014842440374195576,0.014619490131735802,0.014318227767944336,0.01415263582020998,0.013949045911431313,0.013670159503817558,0.013523396104574203,0.013260272331535816,0.013044498860836029,0.012780542485415936,0.012596096843481064,0.012387598864734173,0.012186004780232906,0.011952213011682034,0.011741341091692448,0.011570962145924568,0.011360599659383297,0.011141114868223667,0.010945401154458523,0.010755427181720734,0.010579925961792469,0.01036805659532547,0.010146938264369965,0.009925062768161297,0.00975295715034008,0.009566535241901875,0.009384802542626858,0.00920551735907793,0.009046755731105804,0.008876034989953041,0.00872785598039627,0.008566773496568203,0.008402354083955288,0.008273494429886341,0.00812593661248684,0.007966412231326103,0.00782637856900692,0.007682184688746929,0.007520340848714113,0.007433611433953047,0.007242259569466114,0.007136331405490637,0.006967059802263975,0.006799417547881603,0.006685864180326462,0.0065415059216320515,0.006412169896066189,0.006279973778873682,0.006179867312312126,0.006033303216099739,0.005912196822464466,0.005794868338853121,0.00566733255982399,0.005556258372962475,0.0054673426784574986,0.005347827915102243,0.005234702490270138,0.005144691094756126,0.005043521989136934,0.004955272655934095,0.004852660931646824,0.004771038889884949,0.004671968054026365,0.004596738610416651,0.004501091782003641,0.004424069542437792,0.004326626192778349,0.004253626335412264,0.004165425896644592,0.0041007245890796185,0.004014173056930304,0.003936994355171919,0.0038874782621860504,0.003808983601629734,0.003756491933017969,0.003693902399390936,0.0036297645419836044,0.00356502877548337,0.0035057533532381058,0.0034572849981486797,0.003391349921002984,0.003340618684887886,0.0032857260666787624,0.0032342765480279922,0.00317308004014194,0.003130656434223056,0.003069810103625059,0.003027857281267643,0.0029785337392240763,0.0029437087941914797,0.0028924793004989624,0.002849211450666189,0.002800592454150319,0.002761838026344776,0.002717613708227873,0.0026834928430616856,0.002643188228830695,0.0026013364549726248,0.0025719678960740566,0.0025311834178864956,0.0024921807926148176,0.0024590035900473595,0.0024239225313067436,0.00238788896240294,0.002360536018386483,0.00232081301510334,0.0022857272997498512,0.002255635801702738,0.002222212729975581,0.0021962826140224934,0.002162500750273466,0.0021291938610374928,0.0021080193109810352,0.0020814912859350443,0.002055676421150565,0.002029741881415248,0.002007494680583477,0.0019791792146861553,0.0019550274591892958,0.0019338493002578616,0.0019131468143314123,0.0018874465022236109,0.0018635302549228072,0.001842707279138267,0.0018254535971209407,0.0018034399254247546,0.0017826156690716743,0.0017581019783392549,0.0017415608745068312,0.0017206162447109818,0.0017045505810528994,0.0016825341153889894,0.0016630165046080947,0.001645997748710215,0.00162588432431221,0.0016083888476714492,0.00158946483861655,0.0015748253790661693,0.0015549485106021166,0.001538880169391632,0.0015250729629769921,0.0015070997178554535,0.0014925779541954398,0.0014751992421224713,0.0014606770128011703,0.0014432977186515927,0.0014302035560831428,0.0014152044896036386,0.0014018717920407653,0.0013842533808201551,0.0013703251024708152,0.0013572300085797906,0.0013412775006145239,0.0013306819600984454,0.0013146100100129843,0.0013021094491705298,0.0012911563972011209,0.0012775840004906058,0.0012650828575715423,0.0012519863666966558,0.0012415089877322316,0.0012293646577745676,0.0012166248634457588,0.0012051946250721812,0.0011949549661949277,0.0011842388194054365,0.0011724510695785284,0.0011617346899583936,0.001150541938841343,0.0011406589765101671,0.0011302995262667537,0.0011201781453564763,0.0011100566480308771,0.001099935034289956,0.001090289675630629,0.0010806442005559802,0.0010698077967390418,0.001061591086909175,0.0010514690075069666,0.0010420613689348102,0.0010334871476516128,0.0010247938334941864,0.0010163385886698961,0.001007645158097148,0.0009996660519391298,0.0009921634336933494,0.0009832315845414996,0.0009757286752574146,0.0009676303598098457,0.0009604846709407866,0.000952386180870235,0.0009445258183404803,0.0009371418273076415,0.000929519534111023,0.0009226117981597781,0.0009154658182524145,0.0009080815361812711,0.0009014118695631623,0.0008945039589889348,0.0008878341759555042,0.0008806879632174969,0.0008738989708945155,0.0008673481643199921,0.0008613928221166134,0.0008555566309951246,0.0008482910343445837,0.0008418591460213065,0.000835903687402606,0.0008295908919535577,0.0008235162240453064,0.0008173224050551653,0.0008110094931907952,0.0008057684754021466,0.0007992172613739967,0.0007932615117169917,0.0007880204357206821,0.0007826602668501437,0.0007767044589854777,0.0007711059297434986,0.0007653883076272905,0.000760385300964117,0.0007553822943009436,0.0007499027997255325,0.0007446615491062403,0.0007394201820716262,0.0007348936051130295,0.0007294139941222966,0.0007242917199619114,0.0007197650265879929,0.0007150000892579556,0.0007103541865944862,0.000705470098182559,0.000700466800481081,0.0006960591417737305,0.000691770575940609,0.0006870055221952498,0.0006827168981544673,0.0006775943911634386,0.0006737822550348938,0.0006693744799122214,0.0006652049487456679,0.0006613928126171231,0.0006566275842487812,0.0006525770877487957,0.0006486457423307002,0.0006443570018745959,0.0006407829932868481,0.0006364941946230829,0.0006325627909973264,0.0006288696313276887,0.0006248190766200423,0.0006211258587427437,0.0006179092451930046,0.0006137394811958075,0.000609927112236619,0.0006064721383154392,0.0006026597693562508,0.0005994430393911898,0.0005962263094261289,0.0005922947311773896,0.0005888396990485489,0.0005853846669197083,0.0005821678787469864,0.0005790702416561544,0.0005756151513196528,0.0005721600609831512,0.0005689432728104293,0.0005654881824739277,0.0005626287311315536,0.0005596501869149506,0.0005564333405345678,0.0005535738891921937,0.000550357042811811,0.0005471401382237673,0.0005441615357995033,0.0005413020844571292,0.0005383234238252044,0.0005354639724828303,0.0005329619161784649,0.0005296258023008704,0.0005268854438327253,0.0005240259342826903,0.0005212855176068842,0.0005185451591387391,0.0005159238935448229,0.0005128260818310082,0.0005105622112751007,0.0005075835506431758,0.0005049622268415987,0.0005026984144933522,0.0004998388467356563,0.0004975749761797488,0.0004949536523781717,0.0004924515378661454,0.000490068516228348,0.00048756631440483034,0.0004848258395213634,0.000482442817883566,0.00048029806930571795,0.0004776767164003104,0.0004755319678224623,0.0004731489170808345,0.00047064671525731683,0.00046850196667946875,0.0004664763400796801,0.00046397410915233195,0.00046206763363443315,0.00045980370487086475,0.0004574206250254065,0.00045563330058939755,0.0004536076739896089,0.0004514628672040999,0.00044919890933670104,0.0004472924047149718,0.00044526674901135266,0.00044312194222584367,0.0004412154376041144,0.0004390706308186054,0.0004371640970930457,0.00043501926120370626,0.0004332319076638669,0.00043132537393830717,0.0004295380203984678,0.0004275123355910182,0.0004256058018654585,0.0004239375703036785,0.00042167355422861874,0.0004198861715849489,0.0004180987598374486,0.00041631137719377875,0.00041476229671388865,0.00041261743172071874,0.00041083001997321844,0.00040928093949332833,0.00040749352774582803,0.00040546778473071754,0.00040391870425082743,0.0004021312633994967,0.0004003438516519964,0.0003987947420682758,0.0003967689990531653,0.00039521988946944475,0.0003936707798857242,0.00039200251922011375,0.00039033422945067286,0.0003887851198669523,0.0003871168300975114,0.0003856868715956807,0.0003840185818262398,0.00038235029205679893,0.0003808011533692479,0.00037949037505313754,0.0003778220561798662,0.0003761537664104253,0.0003748429589904845,0.00037317464011721313,0.00037150635034777224,0.00037019551382400095,0.00036864637513644993,0.0003673355677165091,0.0003657863999251276,0.00036435641231946647,0.000362807244528085,0.00036161558819003403,0.0003601856005843729,0.0003586364327929914,0.00035744477645494044,0.00035589560866355896,0.00035446559195406735,0.0003532739356160164,0.0003519630990922451,0.00035065223346464336,0.0003492222458589822,0.0003477922291494906,0.000346362212439999,0.00034517052699811757,0.00034397884155623615,0.0003426679759286344,0.0003413571394048631,0.0003399271226953715,0.0003387354372534901,0.0003375437227077782,0.0003363520372658968,0.00033504117163829505,0.0003337303060106933,0.0003325386205688119,0.0003313469351269305,0.0003303935518488288,0.0003292018664069474,0.00032789100077934563,0.00032669928623363376,0.00032550760079175234,0.00032431588624604046,0.0003232433518860489,0.00032205163734033704,0.00032109825406223536,0.00031990656862035394,0.00031871485407464206,0.0003175231395289302,0.0003164505760651082,0.0003152588615193963,0.00031418632715940475,0.00031323294388130307,0.0003120412293355912,0.0003110878460574895,0.00031001531169749796,0.00030882356804795563,0.00030763185350224376,0.0003067976504098624,0.00030596344731748104,0.0003047717036679387,0.0003036991402041167,0.00030286493711173534,0.000301673193462193,0.000300600629998371,0.00029976642690598965,0.00029869386344216764,0.00029774048016406596,0.0002967870968859643,0.00029583368450403214,0.00029488030122593045,0.00029404606902971864,0.00029297350556589663,0.0002919009421020746,0.0002910667099058628,0.00029023250681348145,0.0002890407631639391,0.00028832571115344763,0.0002874914789572358,0.0002864189154934138,0.000285584683297202,0.00028463127091526985,0.0002836778585333377,0.0002828436263371259,0.0002817710628733039,0.0002809368306770921,0.00028010259848088026,0.00027926836628466845,0.0002783149539027363,0.00027736154152080417,0.00027652730932459235,0.0002755738969426602,0.0002748588449321687,0.00027414379292167723,0.0002731903805397451,0.0002723561483435333,0.000271521887043491,0.0002708068350329995,0.0002698534226510674,0.00026901919045485556,0.0002683041093405336,0.0002673506969586015,0.00026663561584427953,0.00026592056383378804,0.0002649671514518559,0.00026425207033753395,0.00026353701832704246,0.0002628219372127205,0.0002619877050165087,0.0002611534437164664,0.0002603192115202546,0.00025960413040593266,0.00025876989820972085,0.0002580548170953989,0.00025733973598107696,0.00025662468397058547,0.0002559096028562635,0.00025507534155622125,0.000254241080256179,0.0002535260282456875,0.00025281094713136554,0.00025197668583132327,0.0002512616047170013,0.00025054652360267937,0.0002498314715921879,0.00024911639047786593,0.000248401309363544,0.00024768622824922204,0.0002469711471349001,0.00024625606602057815,0.0002455409849062562,0.00024470672360621393,0.00024387246230617166,0.00024327656137757003,0.0002426806604489684,0.00024172721896320581,0.00024125049822032452,0.00024053541710600257,0.00023982033599168062,0.00023910524032544345,0.00023850933939684182,0.0002379134384682402,0.00023719835735391825,0.00023648326168768108,0.00023576818057335913,0.0002351722796447575,0.00023445718397852033,0.0002338612830499187,0.00023326536756940186,0.0002325502864550799,0.00023195437097456306,0.00023123928986024112,0.00023064337437972426,0.0002300474588992074,0.00022933237778488547,0.00022885564249008894,0.00022825974156148732,0.00022754464589525014,0.00022682955022901297,0.00022635281493421644,0.0002256377338198945,0.00022516099852509797,0.0002244459028588608,0.00022396916756406426,0.0002232540718978271,0.0002227773511549458,0.00022218143567442894,0.0002215855201939121,0.00022110878489911556,0.0002203936892328784,0.00021991695393808186,0.00021920185827184469,0.00021860594279132783,0.0002181292074965313,0.00021753329201601446,0.00021705655672121793,0.00021646064124070108,0.00021586472576018423,0.0002153879904653877,0.00021479207498487085,0.00021419614495243877,0.00021371940965764225,0.0002131234941771254,0.00021264675888232887,0.00021205084340181202,0.0002115741081070155,0.0002109781780745834,0.00021038226259406656,0.00020990552729927003,0.00020930961181875318,0.00020883286197204143,0.00020823694649152458,0.00020776021119672805,0.00020728347590193152,0.00020680672605521977,0.00020632999076042324,0.00020585325546562672,0.00020525732543319464,0.00020466140995267779,0.0002040654799202457,0.0002037079248111695,0.00020323118951637298,0.00020251607929822057,0.00020215852418914437,0.0002015625941567123,0.0002012050390476361,0.0002004899288294837,0.00020013237372040749,0.00019965562387369573,0.0001991788885788992,0.00019870213873218745,0.00019822540343739092,0.00019786784832831472,0.00019739109848160297,0.00019691436318680644,0.00019643761334009469,0.00019608005823101848,0.00019560330838430673,0.0001951265730895102,0.00019464982324279845,0.00019405389321036637,0.0001935771433636546,0.00019333878299221396,0.00019274283840786666,0.00019238528329879045,0.0001919085334520787,0.00019143179815728217,0.00019107422849629074,0.00019059749320149422,0.0001902399235405028,0.00018976318824570626,0.00018940561858471483,0.00018892886873800308,0.00018857131362892687,0.00018821375851985067,0.00018773700867313892,0.00018726025882642716,0.0001867835089797154,0.00018654513405635953,0.00018594920402392745,0.0001854724541772157,0.00018523407925385982,0.00018475732940714806,0.0001842805795604363,0.0001839230244513601,0.00018356545479036868,0.00018320789968129247,0.00018273114983458072,0.00018225439998786896,0.0001820160250645131,0.00018153927521780133,0.00018106251081917435,0.00018082413589581847,0.00018034738604910672,0.00018010901112575084,0.00017963226127903908,0.00017927470616996288,0.0001787979417713359,0.0001784403866622597,0.00017808281700126827,0.0001776060671545565,0.00017724849749356508,0.00017677174764685333,0.00017653337272349745,0.0001760566228767857,0.00017581824795342982,0.00017534149810671806,0.00017510310863144696,0.0001746263587847352,0.00017426878912374377,0.00017391123401466757,0.00017355366435367614,0.0001731960946926847,0.0001728385395836085,0.00017248096992261708,0.00017212340026162565,0.00017188502533826977,0.0001714082609396428,0.0001711698860162869,0.00017069313616957515,0.00017045476124621928,0.00017009719158522785,0.00016973962192423642,0.00016926287207752466,0.00016890530241653323,0.0001685477327555418,0.00016830935783218592,0.00016783259343355894,0.00016759421851020306,0.00016711745411157608,0.0001668790791882202,0.00016664070426486433,0.0001662831346038729,0.00016592556494288146,0.00016556799528189003,0.00016532962035853416,0.00016485285595990717,0.0001646144810365513,0.00016425691137555987,0.00016389934171456844,0.00016366096679121256,0.00016342257731594145,0.00016282663273159415,0.00016258825780823827,0.00016223068814724684,0.0001618731184862554,0.00016151554882526398,0.00016127715934999287,0.00016091958968900144,0.00016044282529037446,0.00016020445036701858,0.0001599660754436627,0.00015948931104503572,0.00015925093612167984,0.00015901254664640874,0.0001586549769854173,0.00015841660206206143,0.00015805903240107,0.00015770144818816334,0.00015746307326480746,0.00015710550360381603,0.0001567479339428246,0.0001565095444675535,0.00015627116954419762,0.0001559135998832062,0.00015567521040793508,0.00015531764074694365,0.00015507926582358778,0.00015484087634831667,0.00015448330668732524,0.00015424491721205413,0.00015376816736534238,0.00015352977789007127,0.0001532914029667154,0.0001530530134914443,0.0001525762490928173,0.00015233787416946143,0.00015198028995655477,0.0001517419150331989,0.0001515035255579278,0.00015114595589693636,0.00015090756642166525,0.00015066919149830937,0.0001501924270996824,0.00014995403762441128,0.0001497156627010554,0.0001494772732257843,0.00014923889830242842,0.00014900050882715732,0.0001486429391661659,0.00014840454969089478,0.0001481661747675389,0.00014780859055463225,0.00014745102089364082,0.0001472126314183697,0.00014697425649501383,0.00014673586701974273,0.00014649749209638685,0.00014625910262111574,0.00014590153296012431,0.0001456631434848532,0.0001454247540095821,0.00014506718434859067,0.00014482879487331957,0.00014447122521232814,0.00014411364099942148,0.0001438752660760656,0.0001436368766007945,0.0001433984871255234,0.0001431601122021675,0.0001429217227268964,0.00014256415306590497,0.00014232576359063387,0.00014208737411536276,0.00014184899919200689,0.00014161060971673578,0.00014137222024146467,0.0001411338453181088,0.0001408954558428377,0.00014053787162993103,0.00014029949670657516,0.00014006110723130405,0.00013982271775603294,0.00013958434283267707,0.00013934595335740596,0.00013910756388213485,0.00013886917440686375,0.00013863079948350787,0.00013839241000823677,0.00013815402053296566,0.00013779645087197423,0.00013767725613433868,0.00013731967192143202,0.0001370812824461609,0.00013684290752280504,0.00013660451804753393,0.00013636612857226282,0.00013600854435935616,0.0001357701694360003,0.00013553177996072918,0.00013541258522309363,0.00013505500101018697,0.00013493580627255142,0.00013469743134919554,0.00013445904187392443,0.00013422065239865333,0.00013398226292338222,0.00013374387344811112,0.00013350549852475524,0.00013326710904948413,0.00013302871957421303,0.00013279033009894192,0.00013267113536130637,0.00013243274588603526,0.00013219437096267939,0.00013195598148740828,0.00013171759201213717,0.00013147920253686607,0.00013124081306159496,0.00013100242358632386,0.00013076403411105275,0.00013052565918769687,0.00013040646445006132,0.00013016807497479022,0.0001299296854995191,0.000129691296024248,0.0001294529065489769,0.0001292145170737058,0.0001289761275984347,0.00012885693286079913,0.00012861855793744326,0.00012838016846217215,0.00012814177898690104,0.00012778419477399439,0.00012754580529872328,0.00012730741582345217,0.00012718822108581662,0.00012694983161054552,0.0001267114421352744,0.0001264730526600033,0.0001262346631847322,0.00012611546844709665,0.00012599628826137632,0.00012575789878610522,0.0001255195093108341,0.000125281119835563,0.0001250427303602919,0.00012492353562265635,0.00012468514614738524,0.00012444675667211413,0.00012420836719684303,0.00012396997772157192,0.00012385078298393637,0.00012361239350866526,0.0001234931987710297,0.0001232548092957586,0.00012313561455812305,0.00012289722508285195,0.00012265883560758084,0.00012242044613230973,0.00012218205665703863,0.00012206286191940308,0.00012194366718176752,0.00012170527770649642,0.00012146688823122531,0.00012134769349358976,0.00012110930401831865,0.00012087091454304755,0.000120751719805412,0.00012063252506777644,0.00012039413559250534,0.00012015574611723423,0.00012003655137959868,0.00011979816190432757,0.00011944057769142091,0.00011944057769142091,0.00011920218821614981,0.00011896379146492109,0.00011872540198964998,0.00011860620725201443,0.00011836781777674332,0.00011812942830147222,0.00011801023356383666,0.00011789103882620111,0.00011765264935093,0.0001174142598756589,0.0001174142598756589,0.00011705666838679463,0.00011681827891152352,0.00011669908417388797,0.00011646069469861686,0.00011622230522334576,0.00011622230522334576,0.00011598391574807465,0.00011574551899684593,0.00011562632425921038,0.00011538793478393927,0.00011526874004630372,0.00011514954530866817,0.00011491115583339706,0.00011467275908216834,0.00011467275908216834,0.00011443436960689723,0.00011419598013162613,0.00011407678539399058,0.00011395759065635502,0.0001137191939051263,0.00011359999916749075,0.00011336160969221964,0.00011312322021694854,0.00011312322021694854,0.00011288482346571982,0.00011264643399044871,0.00011252723925281316,0.00011240804451517761,0.00011216964776394889,0.00011205045302631333,0.00011181206355104223,0.00011169286881340668,0.00011157367407577112,0.0001113352773245424,0.00011121608258690685,0.0001110968878492713,0.00011073929636040702,0.00011062010162277147,0.00011038171214750037,0.00011038171214750037,0.00011014331539627165,0.00010990492592100054,0.00010990492592100054,0.00010966652916977182,0.00010942813969450071,0.00010930894495686516,0.00010918975021922961,0.00010907054820563644,0.00010883215873036534,0.00010871296399272978,0.00010859376925509423,0.00010835537250386551,0.00010823617776622996,0.0001081169830285944,0.00010787858627736568,0.00010775939153973013,0.00010764019680209458,0.00010752100206445903,0.0001072826053132303,0.0001072826053132303,0.0001070442158379592,0.00010680581908673048,0.00010668662434909493,0.00010656742961145937,0.00010644822759786621,0.0001062098381225951,0.00010609064338495955,0.00010597144137136638,0.00010573305189609528,0.00010573305189609528,0.00010549465514486656,0.000105375460407231,0.00010525626566959545],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"gridwidth\":2,\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"bgcolor\":\"#E5ECF6\",\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Epochs\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Loss\"}},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"Training Loss\"}},                        {\"responsive\": true}                    ).then(function(){\n","                            \n","var gd = document.getElementById('f511db33-526f-4258-9643-66aa551a5df0');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })                };                            </script>        </div>\n","</body>\n","</html>"]},"metadata":{}}]},{"cell_type":"markdown","source":["##### A probar! üß™"],"metadata":{"id":"9dlS4_X-L3DN"}},{"cell_type":"code","source":["device"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kLHiNXyAvCZJ","executionInfo":{"status":"ok","timestamp":1654902538166,"user_tz":240,"elapsed":10,"user":{"displayName":"Ignacio Meza","userId":"07738957670140287594"}},"outputId":"e96446f6-71f8-40c8-9afa-71c5b570f784"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda')"]},"metadata":{},"execution_count":23}]},{"cell_type":"code","source":["# This is working?, Try the next example!\n","qText = \"'Do you know any joke?'\" # this must classify the label \"funny\"\n","\n","X = torch.tensor([vocab.stoi[t] for t in tokenizer(qText)]).to(device)\n","\n","model.eval()\n","output = model(X, torch.tensor([0], dtype=torch.long).to(device))\n","_, predicted = torch.max(output, dim=1)\n","labels[predicted]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"6IhhAKFXL3eH","executionInfo":{"status":"ok","timestamp":1654902538167,"user_tz":240,"elapsed":9,"user":{"displayName":"Ignacio Meza","userId":"07738957670140287594"}},"outputId":"cc34a896-b336-4f80-bf93-011bcc93545b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'funny'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":24}]},{"cell_type":"markdown","source":["Ya pero prometiste hacer un chatbot, no una simple clasificaci√≥n...."],"metadata":{"id":"udemze3zL549"}},{"cell_type":"markdown","source":["##### Guardamos modelo ü¶∫ (opcional)"],"metadata":{"id":"OpSYGx2tL0tC"}},{"cell_type":"code","source":["# We save de model using pytorch (this is optional, just to learn how to do this in pytorch)\n","data = {\n","\"model_state\": model.state_dict(),\n","\"input_size\": INPUT_SIZE,\n","\"output_size\": OUTPUT_SIZE,\n","\"use_cnn\": USE_CNN,\n","\"labels\": labels\n","        }\n","\n","FILE = \"data.pth\"\n","torch.save(data, FILE)\n","\n","print(f'training complete. file saved to {FILE}')"],"metadata":{"id":"ZBC4TyiqLzDv","executionInfo":{"status":"ok","timestamp":1654902538167,"user_tz":240,"elapsed":8,"user":{"displayName":"Ignacio Meza","userId":"07738957670140287594"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"360b2945-1f90-4618-cbf6-a45cd10d008d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["training complete. file saved to data.pth\n"]}]},{"cell_type":"markdown","source":["##### Chatbot üí¨"],"metadata":{"id":"ZYClbTtsMCjE"}},{"cell_type":"code","source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","with open('star_wars_chatbot.json', 'r') as json_data:\n","    intents = json.load(json_data)\n","\n","FILE = \"data.pth\"\n","data = torch.load(FILE)\n","\n","INPUT_SIZE = data[\"input_size\"]\n","OUTPUT_SIZE = data[\"output_size\"]\n","USE_CNN = data[\"use_cnn\"]\n","labels = data['labels']\n","model_state = data[\"model_state\"]\n","\n","model = CNNClassifier(INPUT_SIZE, num_classes=OUTPUT_SIZE, use_cnn=USE_CNN).to(device)\n","model.load_state_dict(model_state)\n","model.eval()\n","\n","# Dictionary with the answers\n","responses = {key['tag']: key['responses'] for key in dataset['intents']}\n","\n","bot_name = \"GA-97\"\n","print(\"Let's chat! (type 'finish_chat' to finish the chat)\")\n","while True:\n","    q_text = input(\"You: \")\n","    q_text = \"'\"+q_text+\"'\"\n","    if q_text == \"'finish_chat'\":\n","        break\n","\n","    X = torch.tensor([vocab.stoi[t] for t in tokenizer(q_text)]).to(device)\n","    output = model(X, torch.tensor([0], dtype=torch.long).to(device))\n","    _, predicted = torch.max(output, dim=1)\n","\n","    tag = labels[predicted.item()]\n","\n","    probs = torch.softmax(output, dim=1)\n","    prob = probs[0][predicted.item()]\n","    if prob.item() > 0.50:\n","      print(f\"{bot_name}: {random.choice(responses[tag])}\")\n","    else:\n","      print(f\"{bot_name}: My model can't understand you...\")"],"metadata":{"id":"c249zUwiMBxb","colab":{"base_uri":"https://localhost:8080/","height":381},"outputId":"e9a72767-161c-47ac-dbd1-35879008b8a8","executionInfo":{"status":"error","timestamp":1685721493086,"user_tz":240,"elapsed":805,"user":{"displayName":"Gabriel Iturra-Bocaz","userId":"02319919045117626989"}}},"execution_count":null,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-14-1d726aed68f0>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mFILE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"data.pth\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFILE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mINPUT_SIZE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_size\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001b[0m\n\u001b[1;32m    789\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 791\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    792\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data.pth'"]}]},{"cell_type":"markdown","source":["#### Comente los resultados aqu√≠ (0,5 puntos)"],"metadata":{"id":"5Hu2QTuSURCt"}},{"cell_type":"markdown","source":["``Comente los resultados aqu√≠``"],"metadata":{"id":"fdFV63WVUX32"}}]}